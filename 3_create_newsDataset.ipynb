{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3db98ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유 클릭 뉴스 개수: 9100\n",
      "  news_id\n",
      "0  N10032\n",
      "1  N10050\n",
      "2  N10051\n",
      "3  N10056\n",
      "4  N10057\n",
      "저장 완료 → clicked_newsIds_global.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "OUT_CLICKED_IDS = 'clicked_newsIds_global.csv'   # 다음 단계에서 재사용할 파일\n",
    "\n",
    "# =========================\n",
    "# 1) 데이터 불러오기 (헤더 없음)\n",
    "# =========================\n",
    "train = pd.read_csv(PATH_TRAIN, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "dev   = pd.read_csv(PATH_DEV,   sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "# =========================\n",
    "# 2) train+dev 합치기\n",
    "# =========================\n",
    "behaviors = pd.concat([train, dev], ignore_index=True)\n",
    "\n",
    "# =========================\n",
    "# 3) 클릭된 뉴스 고유 ID 수집 (초보자용 for문)\n",
    "#    - Impressions를 공백으로 나눔\n",
    "#    - \"newsId-label\"에서 label이 '1'인 것만 수집\n",
    "#    - rsplit('-', 1)로 뒤에서 한 번만 나눠 안전 파싱\n",
    "# =========================\n",
    "clicked_ids = set()\n",
    "\n",
    "for _, row in behaviors.iterrows():\n",
    "    imps = str(row['Impressions']).split()\n",
    "    for tok in imps:\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        news_id, label = tok.rsplit('-', 1)\n",
    "        if label.strip() == '1':\n",
    "            clicked_ids.add(news_id.strip())\n",
    "\n",
    "# =========================\n",
    "# 4) DataFrame으로 변환 + 저장\n",
    "# =========================\n",
    "clicked_list = sorted(clicked_ids)  # 재현성 위해 정렬(선택)\n",
    "clicked_df = pd.DataFrame({'news_id': clicked_list})\n",
    "\n",
    "print(\"고유 클릭 뉴스 개수:\", len(clicked_df))\n",
    "print(clicked_df.head())\n",
    "\n",
    "# 다음 단계에서 재사용할 수 있도록 저장\n",
    "clicked_df.to_csv(OUT_CLICKED_IDS, index=False)\n",
    "print(f\"저장 완료 → {OUT_CLICKED_IDS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1162a808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  news_id        publish_time        lifespan_end\n",
      "0  N16560 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "1  N50329 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "2  N15134 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "3  N37108 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "4  N58075 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "총 개수: 9100\n",
      "허용 집합 중 publish_time을 찾지 못한 개수: 0\n",
      "저장 완료 → news_times_global.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "PATH_CLICKED_IDS = 'clicked_newsIds_global.csv'     # 1단계에서 만든 파일 (col: news_id)\n",
    "OUT_LIFESPAN = 'news_times_global.csv'          # 전체 lifespan 저장 파일\n",
    "\n",
    "# =========================\n",
    "# 1) 데이터 불러오기 (헤더 없음 주의)\n",
    "# =========================\n",
    "train = pd.read_csv(PATH_TRAIN, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "dev   = pd.read_csv(PATH_DEV,   sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "# 시간 파싱(미리 한 번에) → NaT 허용\n",
    "train['Time'] = pd.to_datetime(train['Time'], errors='coerce')\n",
    "dev['Time']   = pd.to_datetime(dev['Time'],   errors='coerce')\n",
    "\n",
    "# 합치기\n",
    "behaviors = pd.concat([train, dev], ignore_index=True)\n",
    "\n",
    "# =========================\n",
    "# 2) 9,100 허용 집합(클릭 고유 뉴스) 불러오기\n",
    "# =========================\n",
    "allow_df = pd.read_csv(PATH_CLICKED_IDS)\n",
    "allowed_ids = set(str(x).strip() for x in allow_df['news_id'].tolist())\n",
    "\n",
    "# =========================\n",
    "# 3) 각 뉴스의 '최초 노출 시각' 찾기 (라벨 0/1 무관, 허용 집합에 한정)\n",
    "#    - impressions를 공백으로 나눔\n",
    "#    - \"newsId-label\"은 rsplit('-', 1)로 안전 파싱\n",
    "#    - allowed_ids에 속하는 뉴스만 고려\n",
    "#    - 가장 이른 시각을 publish_time으로 저장\n",
    "# =========================\n",
    "first_time = {}  # dict: news_id -> 가장 이른 datetime\n",
    "\n",
    "for _, row in behaviors.iterrows():\n",
    "    t = row['Time']\n",
    "    if pd.isna(t):\n",
    "        continue\n",
    "    tokens = str(row['Impressions']).split()\n",
    "    for tok in tokens:\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        news_id, _ = tok.rsplit('-', 1)\n",
    "        news_id = news_id.strip()\n",
    "\n",
    "        # 허용 집합(= 9,100) 안에서만 처리\n",
    "        if news_id not in allowed_ids:\n",
    "            continue\n",
    "\n",
    "        # 최초 등장 시각 갱신\n",
    "        if news_id not in first_time:\n",
    "            first_time[news_id] = t\n",
    "        else:\n",
    "            if t < first_time[news_id]:\n",
    "                first_time[news_id] = t\n",
    "\n",
    "# =========================\n",
    "# 4) 표로 만들고 lifespan_end = publish_time + 36시간 계산\n",
    "# =========================\n",
    "rows = []\n",
    "for nid, pub_t in first_time.items():\n",
    "    rows.append((nid, pub_t, pub_t + timedelta(hours=36)))\n",
    "\n",
    "news_lifespan_df = pd.DataFrame(rows, columns=['news_id', 'publish_time', 'lifespan_end'])\n",
    "\n",
    "# 정렬은 선택(보기 편하게)\n",
    "news_lifespan_df = news_lifespan_df.sort_values('publish_time').reset_index(drop=True)\n",
    "\n",
    "print(news_lifespan_df.head())\n",
    "print(\"총 개수:\", len(news_lifespan_df))\n",
    "\n",
    "# (참고) 허용 집합에 있었지만 behaviors에서 시간이 잡히지 않은 뉴스가 있는지 체크\n",
    "missing_ids = sorted(list(allowed_ids - set(first_time.keys())))\n",
    "print(\"허용 집합 중 publish_time을 찾지 못한 개수:\", len(missing_ids))\n",
    "# 필요하면 아래 주석 해제해서 어떤 ID들인지 확인\n",
    "# print(missing_ids[:20])\n",
    "\n",
    "# =========================\n",
    "# 5) 저장 (다음 단계에서 재사용)\n",
    "# =========================\n",
    "news_lifespan_df.to_csv(OUT_LIFESPAN, index=False)\n",
    "print(f\"저장 완료 → {OUT_LIFESPAN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cff0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 train 행 개수: 156965\n",
      "한 행에 impression-1(클릭)이 2개 이상인 행 개수: 43077\n",
      "113888\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "# 헤더 없음 주의\n",
    "train = pd.read_csv('download/MINDsmall_train/behaviors.tsv', sep='\\t',\n",
    "                    names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "def count_pos_in_row(imps_str):\n",
    "    \"\"\"한 행의 Impressions에서 -1(클릭) 개수 세기 (초보자용 안전 파싱)\"\"\"\n",
    "    if pd.isna(imps_str):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for token in str(imps_str).split():\n",
    "        if '-' not in token:\n",
    "            continue\n",
    "        news_id, label = token.rsplit('-', 1)\n",
    "        if label.strip() == '1':\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "train['pos_cnt'] = train['Impressions'].apply(count_pos_in_row)\n",
    "\n",
    "rows_with_multi_pos = (train['pos_cnt'] >= 2).sum()\n",
    "print(\"전체 train 행 개수:\", len(train))\n",
    "print(\"한 행에 impression-1(클릭)이 2개 이상인 행 개수:\", rows_with_multi_pos)\n",
    "print(len(train)-rows_with_multi_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46d2eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== train =====\n",
      "원본 행수: 156,965  →  예상 변경 후: 236,344  (Δ +79,379)\n",
      "- Time이 NaT인 행 수: 0\n",
      "- 허용집합 기준 -1이 2개 이상인 행 수: 43,077\n",
      "- 그 행들에서의 -1 총합: 122,456\n",
      "\n",
      "[-1 개수 분포 (허용집합 기준)]\n",
      "2개 -1: 25571행\n",
      "3개 -1: 9263행\n",
      "4개 -1: 3975행\n",
      "5개 -1: 1957행\n",
      "6개 -1: 942행\n",
      "7개 -1: 515행\n",
      "8개 -1: 296행\n",
      "9개 -1: 198행\n",
      "10개 -1: 117행\n",
      "11개 -1: 81행\n",
      "12개 -1: 46행\n",
      "13개 -1: 38행\n",
      "14개 -1: 22행\n",
      "15개 -1: 17행\n",
      "16개 -1: 10행\n",
      "17개 -1: 6행\n",
      "18개 -1: 9행\n",
      "19개 -1: 2행\n",
      "20개 -1: 1행\n",
      "21개 -1: 2행\n",
      "22개 -1: 1행\n",
      "23개 -1: 1행\n",
      "24개 -1: 1행\n",
      "25개 -1: 1행\n",
      "26개 -1: 2행\n",
      "27개 -1: 1행\n",
      "31개 -1: 1행\n",
      "35개 -1: 1행\n",
      "\n",
      "===== dev =====\n",
      "원본 행수: 73,152  →  예상 변경 후: 111,383  (Δ +38,231)\n",
      "- Time이 NaT인 행 수: 0\n",
      "- 허용집합 기준 -1이 2개 이상인 행 수: 21,085\n",
      "- 그 행들에서의 -1 총합: 59,316\n",
      "\n",
      "[-1 개수 분포 (허용집합 기준)]\n",
      "2개 -1: 12707행\n",
      "3개 -1: 4443행\n",
      "4개 -1: 1911행\n",
      "5개 -1: 932행\n",
      "6개 -1: 426행\n",
      "7개 -1: 268행\n",
      "8개 -1: 166행\n",
      "9개 -1: 83행\n",
      "10개 -1: 61행\n",
      "11개 -1: 34행\n",
      "12개 -1: 17행\n",
      "13개 -1: 11행\n",
      "14개 -1: 5행\n",
      "15개 -1: 5행\n",
      "16개 -1: 6행\n",
      "17개 -1: 3행\n",
      "18개 -1: 2행\n",
      "19개 -1: 2행\n",
      "20개 -1: 1행\n",
      "21개 -1: 1행\n",
      "24개 -1: 1행\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "PATH_TRAIN_LIFE = 'train_lifespan.csv'  # ['news_id','publish_time','lifespan_end']\n",
    "PATH_DEV_LIFE   = 'dev_lifespan.csv'\n",
    "\n",
    "def count_allowed_pos(imps_str, allowed_ids):\n",
    "    \"\"\"허용 집합(=lifespan news_id) 기준으로 -1(클릭) 개수 세기\"\"\"\n",
    "    if pd.isna(imps_str):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for tok in str(imps_str).split():\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        nid, lab = tok.rsplit('-', 1)\n",
    "        if (lab.strip() == '1') and (nid.strip() in allowed_ids):\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def analyze_split(beh_path, life_path, split_name):\n",
    "    # 1) 데이터 로드 + 시간 파싱\n",
    "    df = pd.read_csv(beh_path, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "\n",
    "    # 2) 허용 집합(= 해당 split lifespan의 news_id)\n",
    "    life_df = pd.read_csv(life_path)\n",
    "    allowed_ids = set(str(x).strip() for x in life_df['news_id'].dropna().tolist())\n",
    "\n",
    "    # 3) 4단계 규칙에 맞춰 '예상 변경 후 행수'와 분포 계산\n",
    "    orig_rows = len(df)\n",
    "    new_rows = 0\n",
    "\n",
    "    rows_with_multi = 0\n",
    "    sum_pos_in_multi = 0\n",
    "    dist = {}  # {양성개수: 행 수}\n",
    "\n",
    "    rows_time_nat = 0\n",
    "    rows_with_at_least_one_allowed_pos = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        pos_cnt_allowed = count_allowed_pos(row['Impressions'], allowed_ids)\n",
    "        is_nat = pd.isna(row['Time'])\n",
    "\n",
    "        # 분포(허용 집합 기준)\n",
    "        if pos_cnt_allowed >= 2:\n",
    "            rows_with_multi += 1\n",
    "            sum_pos_in_multi += pos_cnt_allowed\n",
    "            dist[pos_cnt_allowed] = dist.get(pos_cnt_allowed, 0) + 1\n",
    "\n",
    "        # 4단계 확장 규칙과 동일하게 '예상 새 행수' 누적\n",
    "        if (not is_nat) and (pos_cnt_allowed >= 1):\n",
    "            new_rows += pos_cnt_allowed     # 양성 m개면 m행\n",
    "            rows_with_at_least_one_allowed_pos += 1\n",
    "        else:\n",
    "            new_rows += 1                   # NaT이거나 양성 0개면 1행 유지\n",
    "            if is_nat:\n",
    "                rows_time_nat += 1\n",
    "\n",
    "    delta = new_rows - orig_rows\n",
    "\n",
    "    # 4) 출력 (split 별)\n",
    "    print(f\"\\n===== {split_name} =====\")\n",
    "    print(f\"원본 행수: {orig_rows:,}  →  예상 변경 후: {new_rows:,}  (Δ {delta:+,})\")\n",
    "    print(f\"- Time이 NaT인 행 수: {rows_time_nat:,}\")\n",
    "    print(f\"- 허용집합 기준 -1이 2개 이상인 행 수: {rows_with_multi:,}\")\n",
    "    print(f\"- 그 행들에서의 -1 총합: {sum_pos_in_multi:,}\")\n",
    "\n",
    "    print(\"\\n[-1 개수 분포 (허용집합 기준)]\")\n",
    "    for k in sorted(dist):\n",
    "        print(f\"{k}개 -1: {dist[k]}행\")\n",
    "\n",
    "# 실행\n",
    "analyze_split(PATH_TRAIN, PATH_TRAIN_LIFE, 'train')\n",
    "analyze_split(PATH_DEV,   PATH_DEV_LIFE,   'dev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ff05c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 허용 집합 로드: clicked_newsIds_global.csv (개수=9100)\n",
      "완료: 수명표 저장\n",
      " - train_lifespan.csv 8069\n",
      " - dev_lifespan.csv 3221\n",
      "허용 ID 중 train에 등장하지 않은 개수: 1031\n",
      "허용 ID 중 dev에 등장하지 않은 개수  : 5879\n"
     ]
    }
   ],
   "source": [
    "# A_make_lifespan_tables.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# =========================================================\n",
    "# 설정\n",
    "# =========================================================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "# 파일 경로 (필요시 수정)\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "\n",
    "# 9,100 허용 집합(클릭 고유 뉴스 ID) 파일\n",
    "PATH_CLICKED_IDS = 'clicked_newsIds_global.csv'   # (1단계 산출물, col: news_id)\n",
    "\n",
    "# 출력 파일 (split별 lifespan)\n",
    "OUT_TRAIN_LIFE = 'train_lifespan.csv'   # ['news_id','publish_time','lifespan_end']\n",
    "OUT_DEV_LIFE   = 'dev_lifespan.csv'\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 0) 보조 함수\n",
    "# =========================================================\n",
    "def build_clicked_set(df):\n",
    "    \"\"\"\n",
    "    df 전체에서 클릭(-1)된 뉴스의 고유 ID 집합을 만든다.\n",
    "    - Impressions를 공백으로 나눔\n",
    "    - \"newsId-label\"에서 label이 '1'인 것만 수집\n",
    "    - rsplit('-', 1)로 뒤에서 한 번만 분리 (안전)\n",
    "    \"\"\"\n",
    "    s = set()\n",
    "    for _, row in df.iterrows():\n",
    "        tokens = str(row['Impressions']).split()\n",
    "        for tok in tokens:\n",
    "            if '-' not in tok:\n",
    "                continue\n",
    "            nid, lbl = tok.rsplit('-', 1)\n",
    "            if lbl.strip() == '1':\n",
    "                s.add(nid.strip())\n",
    "    return s\n",
    "\n",
    "\n",
    "def build_lifespan_table(df, allowed_ids):\n",
    "    \"\"\"\n",
    "    split 하나에 대한 수명표 만들기 (허용 집합에 포함된 뉴스만):\n",
    "      - 각 뉴스ID의 '해당 split에서의 최초 등장 시각'을 publish_time으로\n",
    "      - lifespan_end = publish_time + 36시간\n",
    "      - 반환: DataFrame(columns=['news_id','publish_time','lifespan_end'])\n",
    "    \"\"\"\n",
    "    first_time = {}  # dict: news_id -> 가장 이른 datetime\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        t = row['Time']  # 이 행의 노출 시각\n",
    "        if pd.isna(t):\n",
    "            continue\n",
    "        tokens = str(row['Impressions']).split()\n",
    "        for token in tokens:\n",
    "            if '-' not in token:\n",
    "                continue\n",
    "            news_id, _ = token.rsplit('-', 1)\n",
    "            news_id = news_id.strip()\n",
    "\n",
    "            # ★ 허용 집합(9,100)에 포함된 뉴스만 대상\n",
    "            if news_id not in allowed_ids:\n",
    "                continue\n",
    "\n",
    "            # 최초 등장 시각 갱신\n",
    "            if news_id not in first_time:\n",
    "                first_time[news_id] = t\n",
    "            else:\n",
    "                if t < first_time[news_id]:\n",
    "                    first_time[news_id] = t\n",
    "\n",
    "    # 표로 변환\n",
    "    rows = []\n",
    "    for nid, pub_t in first_time.items():\n",
    "        lifespan_end = pub_t + timedelta(hours=36)\n",
    "        rows.append((nid, pub_t, lifespan_end))\n",
    "\n",
    "    life_df = pd.DataFrame(rows, columns=['news_id', 'publish_time', 'lifespan_end'])\n",
    "    return life_df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) behaviors 불러오기 (헤더 없음 주의) + 시간 파싱\n",
    "# =========================================================\n",
    "train = pd.read_csv(PATH_TRAIN, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "dev   = pd.read_csv(PATH_DEV,   sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "train['Time'] = pd.to_datetime(train['Time'], errors='coerce')\n",
    "dev['Time']   = pd.to_datetime(dev['Time'],   errors='coerce')\n",
    "\n",
    "# 허용 집합 파일이 없으면 즉석에서 생성 (train+dev 합쳐서 클릭 뉴스 뽑음)\n",
    "if os.path.exists(PATH_CLICKED_IDS):\n",
    "    allow_df = pd.read_csv(PATH_CLICKED_IDS)\n",
    "    allowed_ids = set(str(x).strip() for x in allow_df['news_id'].dropna().tolist())\n",
    "    print(f\"[OK] 허용 집합 로드: {PATH_CLICKED_IDS} (개수={len(allowed_ids)})\")\n",
    "else:\n",
    "    print(f\"[INFO] 허용 집합 파일 없음 → 즉석 생성: {PATH_CLICKED_IDS}\")\n",
    "    both = pd.concat([train, dev], ignore_index=True)\n",
    "    allowed_ids = build_clicked_set(both)\n",
    "    pd.DataFrame({'news_id': sorted(allowed_ids)}).to_csv(PATH_CLICKED_IDS, index=False)\n",
    "    print(f\"[OK] 생성 및 저장 완료: {PATH_CLICKED_IDS} (개수={len(allowed_ids)})\")\n",
    "\n",
    "# =========================================================\n",
    "# 2) split별 수명표 생성 & 저장 (★ train/dev 각각, 그리고 ★ 허용 집합 제한 적용)\n",
    "# =========================================================\n",
    "train_life = build_lifespan_table(train, allowed_ids)\n",
    "dev_life   = build_lifespan_table(dev,   allowed_ids)\n",
    "\n",
    "train_life.to_csv(OUT_TRAIN_LIFE, index=False)\n",
    "dev_life.to_csv(OUT_DEV_LIFE,     index=False)\n",
    "\n",
    "print(\"완료: 수명표 저장\")\n",
    "print(\" -\", OUT_TRAIN_LIFE, len(train_life))\n",
    "print(\" -\", OUT_DEV_LIFE,   len(dev_life))\n",
    "\n",
    "# (선택) 각 split에서 허용 집합 중 등장하지 않은 ID 수 체크(모니터링용)\n",
    "miss_train = len(allowed_ids - set(train_life['news_id']))\n",
    "miss_dev   = len(allowed_ids - set(dev_life['news_id']))\n",
    "print(f\"허용 ID 중 train에 등장하지 않은 개수: {miss_train}\")\n",
    "print(f\"허용 ID 중 dev에 등장하지 않은 개수  : {miss_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de8b6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ImpressionID  UserID                Time  \\\n",
      "0             1  U13740 2019-11-11 09:05:58   \n",
      "1             2  U91836 2019-11-12 18:11:30   \n",
      "2             3  U73700 2019-11-14 07:01:48   \n",
      "3             4  U34670 2019-11-11 05:28:05   \n",
      "4             5   U8125 2019-11-12 16:11:21   \n",
      "\n",
      "                                             History  \\\n",
      "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
      "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
      "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
      "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
      "4                        N10078 N56514 N14904 N33740   \n",
      "\n",
      "                                         Impressions  \\\n",
      "0                                  N55689-1 N35729-0   \n",
      "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...   \n",
      "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...   \n",
      "3                N35729-0 N33632-0 N49685-1 N27581-0   \n",
      "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...   \n",
      "\n",
      "                                     Impressions_new  \n",
      "0  N55689-1 N10459-0 N26643-0 N58965-0 N3369-0 N5...  \n",
      "1  N17059-1 N57226-0 N28148-0 N13680-0 N15505-0 N...  \n",
      "2  N23814-1 N19050-0 N34869-0 N62054-0 N22301-0 N...  \n",
      "3  N49685-1 N50939-0 N11702-0 N21611-0 N47858-0 N...  \n",
      "4  N8400-1 N56818-0 N51154-0 N21741-0 N15269-0 N4...  \n",
      "   ImpressionID  UserID                Time  \\\n",
      "0             1  U80234 2019-11-15 12:37:50   \n",
      "1             2  U60458 2019-11-15 07:11:50   \n",
      "2             3  U44190 2019-11-15 09:55:12   \n",
      "3             4  U87380 2019-11-15 15:12:46   \n",
      "4             5   U9444 2019-11-15 08:25:46   \n",
      "\n",
      "                                             History  \\\n",
      "0  N55189 N46039 N51741 N53234 N11276 N264 N40716...   \n",
      "1  N58715 N32109 N51180 N33438 N54827 N28488 N611...   \n",
      "2  N56253 N1150 N55189 N16233 N61704 N51706 N5303...   \n",
      "3  N63554 N49153 N28678 N23232 N43369 N58518 N444...   \n",
      "4                 N51692 N18285 N26015 N22679 N55556   \n",
      "\n",
      "                                         Impressions  \\\n",
      "0  N28682-0 N48740-0 N31958-1 N34130-0 N6916-0 N5...   \n",
      "1  N20036-0 N23513-1 N32536-0 N46976-0 N35216-0 N...   \n",
      "2  N36779-0 N62365-0 N58098-0 N5472-0 N13408-0 N5...   \n",
      "3  N6950-0 N60215-0 N6074-0 N11930-0 N6916-0 N248...   \n",
      "4  N5940-1 N23513-0 N49285-0 N23355-0 N19990-0 N3...   \n",
      "\n",
      "                                     Impressions_new  \n",
      "0  N31958-1 N436-0 N23110-0 N25191-0 N60660-0 N12...  \n",
      "1  N23513-1 N41596-0 N42767-0 N46810-0 N32854-0 N...  \n",
      "2  N5940-1 N39213-0 N49879-0 N6582-0 N42981-0 N11...  \n",
      "3  N15347-1 N65036-0 N13471-0 N3174-0 N22029-0 N3...  \n",
      "4  N5940-1 N64305-0 N32806-0 N28895-0 N41934-0 N6...  \n",
      "\n",
      "===== 행 개수 비교 =====\n",
      "train  | 원본: 156,965  →  변경 후: 236,344  (Δ +79,379)\n",
      "dev    | 원본: 73,152    →  변경 후: 111,383    (Δ +38,231)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import timedelta\n",
    "\n",
    "random.seed(42)  # 무작위 샘플 재현용 시드\n",
    "\n",
    "# =========================================================\n",
    "# 설정\n",
    "# =========================================================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "# 파일 경로 (필요 시 수정)\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "\n",
    "# (A 단계에서 미리 만든 수명표 파일들: ★ 9,100 허용 집합만 포함되어 있어야 함)\n",
    "PATH_TRAIN_LIFE = 'train_lifespan.csv'  # ['news_id','publish_time','lifespan_end']\n",
    "PATH_DEV_LIFE   = 'dev_lifespan.csv'\n",
    "\n",
    "K_NEG = 20  # 음성 개수 (한 행당: 양성 1 + 음성 K_NEG)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 공용 보조 함수들 (초보자 스타일)\n",
    "# =========================================================\n",
    "def get_all_positives(imps_str):\n",
    "    \"\"\"\n",
    "    Impressions 문자열에서 -1(클릭)인 모든 뉴스ID 리스트를 반환.\n",
    "    예: \"N1-0 N2-1 N3-1 N4-0\" -> [\"N2\", \"N3\"]\n",
    "    클릭이 하나도 없으면 [] 반환.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if pd.isna(imps_str):\n",
    "        return result\n",
    "    tokens = str(imps_str).split()\n",
    "    for token in tokens:\n",
    "        if '-' not in token:\n",
    "            continue\n",
    "        news_id, label = token.rsplit('-', 1)\n",
    "        if label.strip() == '1':  # ★ 꼭 -1 인 것만 양성\n",
    "            result.append(news_id.strip())\n",
    "    return result\n",
    "\n",
    "def floor_to_hour(dt):\n",
    "    \"\"\"\n",
    "    datetime을 '정시'로 내림.\n",
    "    예: 2020-06-14 13:27 -> 2020-06-14 13:00\n",
    "    \"\"\"\n",
    "    if pd.isna(dt):\n",
    "        return None\n",
    "    return dt.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "def build_user_clicked(df):\n",
    "    \"\"\"\n",
    "    df 전체를 훑어 사용자별 '과거/미래 포함, 한 번이라도 클릭(-1)한 뉴스ID' 집합 생성.\n",
    "    반환: dict { user_id: set(news_id) }\n",
    "    \"\"\"\n",
    "    user_clicked = {}\n",
    "    for _, row in df.iterrows():\n",
    "        uid = row['UserID']\n",
    "        tokens = str(row['Impressions']).split()\n",
    "        for token in tokens:\n",
    "            if '-' not in token:\n",
    "                continue\n",
    "            news_id, label = token.rsplit('-', 1)\n",
    "            if label.strip() == '1':\n",
    "                if uid not in user_clicked:\n",
    "                    user_clicked[uid] = set()\n",
    "                user_clicked[uid].add(news_id.strip())\n",
    "    return user_clicked\n",
    "\n",
    "def build_alive_buckets_and_map(life_df):\n",
    "    \"\"\"\n",
    "    시간 버킷(정시 단위) → 그 시간에 '살아있는' 뉴스ID 리스트를 빠르게 얻기 위한 사전 구성.\n",
    "    또한 정확한 분 단위 판정을 위해 news_id -> (publish_time, lifespan_end) map도 함께 생성.\n",
    "\n",
    "    buckets: dict { hour_dt: [news_id, ...] }\n",
    "    life_map: dict { news_id: (publish_time, lifespan_end) }\n",
    "    \"\"\"\n",
    "    buckets = {}\n",
    "    life_map = {}\n",
    "\n",
    "    for _, row in life_df.iterrows():\n",
    "        nid   = str(row['news_id'])\n",
    "        start = row['publish_time']\n",
    "        end   = row['lifespan_end']\n",
    "        life_map[nid] = (start, end)\n",
    "\n",
    "        if pd.isna(start) or pd.isna(end):\n",
    "            continue\n",
    "\n",
    "        cur = floor_to_hour(start)\n",
    "        # cur 가 end 이전까지만(행 기준 조건: row_time < lifespan_end)\n",
    "        while cur < end:\n",
    "            if cur not in buckets:\n",
    "                buckets[cur] = []\n",
    "            buckets[cur].append(nid)\n",
    "            cur = cur + timedelta(hours=1)\n",
    "\n",
    "    return buckets, life_map\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# split 하나를 처리: 다중 양성 행 → '양성 개수만큼 행 확장' + 음성 샘플링\n",
    "#  - ★ 양성도 lifespan(= 허용 집합) 안에 있는 뉴스만 사용하도록 필터링\n",
    "#  - 음성은 lifespan 버킷에서 선택(= 허용 집합 내부) + 유저 과거/미래 미클릭 + HISTORY 미포함 + 양성과 비중복\n",
    "# =========================================================\n",
    "def rebuild_for_split_with_expand(beh_path, life_path, k_neg):\n",
    "    # 1) behaviors 불러오기 (헤더 없음)\n",
    "    df = pd.read_csv(beh_path, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "\n",
    "    # 2) 수명표 로드 + 버킷/맵 생성\n",
    "    life_df = pd.read_csv(life_path, parse_dates=['publish_time','lifespan_end'])\n",
    "    alive_buckets, life_map = build_alive_buckets_and_map(life_df)\n",
    "\n",
    "    # 3) 사용자별 '클릭했던 뉴스 집합' (해당 split 전체 기준)\n",
    "    u_clicked = build_user_clicked(df)\n",
    "\n",
    "    # 4) 결과를 담을 '확장된 행' 리스트\n",
    "    expanded_rows = []\n",
    "\n",
    "    # 5) 각 원본 행을 순회\n",
    "    for _, row in df.iterrows():\n",
    "        row_time = row['Time']\n",
    "        uid      = row['UserID']\n",
    "        original = row['Impressions']\n",
    "\n",
    "        # (a) 이 행의 모든 양성 뉴스ID 수집\n",
    "        pos_list_all = get_all_positives(original)\n",
    "        # (a-1) ★ 양성도 허용 집합(= life_map 키) 안의 뉴스만 사용\n",
    "        allowed_pos = []\n",
    "        for nid in pos_list_all:\n",
    "            if nid in life_map:\n",
    "                allowed_pos.append(nid)\n",
    "\n",
    "        # (b) 양성이 하나도 없거나 시간 파싱 실패라면 → 원본 그 상태로 1행만 유지\n",
    "        if (len(allowed_pos) == 0) or pd.isna(row_time):\n",
    "            new_row = {\n",
    "                'ImpressionID': row['ImpressionID'],\n",
    "                'UserID': row['UserID'],\n",
    "                'Time': row['Time'],\n",
    "                'History': row['History'],\n",
    "                'Impressions': row['Impressions'],\n",
    "                'Impressions_new': row['Impressions']  # 그대로 둠(원하면 \"\"로 비울 수도 있음)\n",
    "            }\n",
    "            expanded_rows.append(new_row)\n",
    "            continue\n",
    "\n",
    "        # (c) 양성이 여러 개인 경우 → '양성 1개당 1행'씩 복제 생성\n",
    "        hour_key = floor_to_hour(row_time)\n",
    "        candidate_ids_bucket = []\n",
    "        if (hour_key is not None) and (hour_key in alive_buckets):\n",
    "            candidate_ids_bucket = alive_buckets[hour_key][:]\n",
    "        # 중복 제거\n",
    "        candidate_ids_bucket = list(set(candidate_ids_bucket))\n",
    "\n",
    "        # History set 준비\n",
    "        history_set = set()\n",
    "        if pd.notna(row['History']):\n",
    "            for nid in str(row['History']).split():\n",
    "                history_set.add(nid)\n",
    "\n",
    "        # pos마다 한 행 생성\n",
    "        for pos_news in allowed_pos:\n",
    "            # 1) 후보 시작: 버킷에서 꺼낸 리스트 → 정밀 시간조건으로 다시 필터링\n",
    "            precise_candidates = []\n",
    "            for nid in candidate_ids_bucket:\n",
    "                pub_t, end_t = life_map.get(nid, (None, None))\n",
    "                if (pub_t is None) or (end_t is None):\n",
    "                    continue\n",
    "                if (pub_t <= row_time) and (row_time < end_t):\n",
    "                    precise_candidates.append(nid)\n",
    "\n",
    "            # 2) 사용자 과거/미래 클릭 제외\n",
    "            clicked_set = u_clicked.get(uid, set())\n",
    "            tmp = []\n",
    "            for nid in precise_candidates:\n",
    "                if nid not in clicked_set:\n",
    "                    tmp.append(nid)\n",
    "            precise_candidates = tmp\n",
    "\n",
    "            # 3) History 제외\n",
    "            tmp = []\n",
    "            for nid in precise_candidates:\n",
    "                if nid not in history_set:\n",
    "                    tmp.append(nid)\n",
    "            precise_candidates = tmp\n",
    "\n",
    "            # 4) 양성과 중복 금지\n",
    "            tmp = []\n",
    "            for nid in precise_candidates:\n",
    "                if nid != pos_news:\n",
    "                    tmp.append(nid)\n",
    "            precise_candidates = tmp\n",
    "\n",
    "            # 5) 음성 무작위 추출 (부족하면 있는 만큼만)\n",
    "            if len(precise_candidates) >= k_neg:\n",
    "                neg_news = random.sample(precise_candidates, k_neg)\n",
    "            else:\n",
    "                neg_news = precise_candidates\n",
    "\n",
    "            # 6) 최종 Impressions 문자열 (양성 -1, 음성 -0)\n",
    "            parts = [f\"{pos_news}-1\"]\n",
    "            for nid in neg_news:\n",
    "                parts.append(f\"{nid}-0\")\n",
    "            new_imps_str = \" \".join(parts)\n",
    "\n",
    "            # 7) 원본 행을 복제하되, Impressions_new만 다르게 설정\n",
    "            new_row = {\n",
    "                'ImpressionID': row['ImpressionID'],   # ★ 동일 ID 유지(필요시 새 ID 부여 가능)\n",
    "                'UserID': row['UserID'],\n",
    "                'Time': row['Time'],\n",
    "                'History': row['History'],\n",
    "                'Impressions': row['Impressions'],\n",
    "                'Impressions_new': new_imps_str\n",
    "            }\n",
    "            expanded_rows.append(new_row)\n",
    "\n",
    "    # 6) 확장된 행들로 DataFrame 생성 (원본 5컬럼 + Impressions_new)\n",
    "    out_df = pd.DataFrame(expanded_rows, columns=BEHAVIOR_COLUMNS + ['Impressions_new'])\n",
    "    return df, out_df   # 원본 df도 함께 반환하여 개수 비교에 사용\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 실행: train/dev 각각 처리 + 행 개수 비교 출력\n",
    "# =========================================================\n",
    "# train\n",
    "train_orig_df, train_final = rebuild_for_split_with_expand(PATH_TRAIN, PATH_TRAIN_LIFE, K_NEG)\n",
    "# dev\n",
    "dev_orig_df,   dev_final   = rebuild_for_split_with_expand(PATH_DEV,   PATH_DEV_LIFE,   K_NEG)\n",
    "\n",
    "# --- 결과 미리보기\n",
    "print(train_final.head())\n",
    "print(dev_final.head())\n",
    "\n",
    "# --- 행 개수 비교 출력\n",
    "orig_train_rows = len(train_orig_df)\n",
    "orig_dev_rows   = len(dev_orig_df)\n",
    "new_train_rows  = len(train_final)\n",
    "new_dev_rows    = len(dev_final)\n",
    "\n",
    "print(\"\\n===== 행 개수 비교 =====\")\n",
    "print(f\"train  | 원본: {orig_train_rows:,}  →  변경 후: {new_train_rows:,}  (Δ {new_train_rows - orig_train_rows:+,})\")\n",
    "print(f\"dev    | 원본: {orig_dev_rows:,}    →  변경 후: {new_dev_rows:,}    (Δ {new_dev_rows - orig_dev_rows:+,})\")\n",
    "\n",
    "# (선택) 저장\n",
    "train_final.to_csv('train_expanded.tsv', sep='\\t', index=False)\n",
    "dev_final.to_csv('dev_expanded.tsv',   sep='\\t', index=False)\n",
    "\n",
    "# (선택) 학습 포맷(5컬럼)으로 쓰려면, Impressions ← Impressions_new 교체 + 5컬럼만:\n",
    "train_out = train_final.copy()\n",
    "train_out['Impressions'] = train_out['Impressions_new']\n",
    "train_out = train_out[BEHAVIOR_COLUMNS]\n",
    "train_out.to_csv('train_rebuilt_expanded.tsv', sep='\\t', header=False, index=False)\n",
    "\n",
    "dev_out = dev_final.copy()\n",
    "dev_out['Impressions'] = dev_out['Impressions_new']\n",
    "dev_out = dev_out[BEHAVIOR_COLUMNS]\n",
    "dev_out.to_csv('dev_rebuilt_expanded.tsv', sep='\\t', header=False, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
