{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0777f5a",
   "metadata": {},
   "source": [
    "### 클릭한 뉴스들 중 고유한 뉴스 ID 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3db98ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유 클릭 뉴스 개수: 9100\n",
      "  news_id\n",
      "0  N10032\n",
      "1  N10050\n",
      "2  N10051\n",
      "3  N10056\n",
      "4  N10057\n",
      "저장 완료 → clicked_newsIds_global.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "OUT_CLICKED_IDS = 'clicked_newsIds_global.csv'   # 다음 단계에서 재사용할 파일\n",
    "\n",
    "# =========================\n",
    "# 1) 데이터 불러오기 (헤더 없음)\n",
    "# =========================\n",
    "train = pd.read_csv(PATH_TRAIN, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "dev   = pd.read_csv(PATH_DEV,   sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "# =========================\n",
    "# 2) train+dev 합치기\n",
    "# =========================\n",
    "behaviors = pd.concat([train, dev], ignore_index=True)\n",
    "\n",
    "# =========================\n",
    "# 3) 클릭된 뉴스 고유 ID 수집 (초보자용 for문)\n",
    "#    - Impressions를 공백으로 나눔\n",
    "#    - \"newsId-label\"에서 label이 '1'인 것만 수집\n",
    "#    - rsplit('-', 1)로 뒤에서 한 번만 나눠 안전 파싱\n",
    "# =========================\n",
    "clicked_ids = set()\n",
    "\n",
    "for _, row in behaviors.iterrows():\n",
    "    imps = str(row['Impressions']).split()\n",
    "    for tok in imps:\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        news_id, label = tok.rsplit('-', 1)\n",
    "        if label.strip() == '1':\n",
    "            clicked_ids.add(news_id.strip())\n",
    "\n",
    "# =========================\n",
    "# 4) DataFrame으로 변환 + 저장\n",
    "# =========================\n",
    "clicked_list = sorted(clicked_ids)  # 재현성 위해 정렬(선택)\n",
    "clicked_df = pd.DataFrame({'news_id': clicked_list})\n",
    "\n",
    "print(\"고유 클릭 뉴스 개수:\", len(clicked_df))\n",
    "print(clicked_df.head())\n",
    "\n",
    "# 다음 단계에서 재사용할 수 있도록 저장\n",
    "clicked_df.to_csv(OUT_CLICKED_IDS, index=False)\n",
    "print(f\"저장 완료 → {OUT_CLICKED_IDS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1162a808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  news_id        publish_time        lifespan_end\n",
      "0  N16560 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "1  N50329 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "2  N15134 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "3  N37108 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "4  N58075 2019-11-09 00:00:19 2019-11-10 12:00:19\n",
      "총 개수: 9100\n",
      "허용 집합 중 publish_time을 찾지 못한 개수: 0\n",
      "저장 완료 → news_times_global.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "PATH_CLICKED_IDS = 'clicked_newsIds_global.csv'     # 1단계에서 만든 파일 (col: news_id)\n",
    "OUT_LIFESPAN = 'news_times_global.csv'          # 전체 lifespan 저장 파일\n",
    "\n",
    "# =========================\n",
    "# 1) 데이터 불러오기 (헤더 없음 주의)\n",
    "# =========================\n",
    "train = pd.read_csv(PATH_TRAIN, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "dev   = pd.read_csv(PATH_DEV,   sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "# 시간 파싱(미리 한 번에) → NaT 허용\n",
    "train['Time'] = pd.to_datetime(train['Time'], errors='coerce')\n",
    "dev['Time']   = pd.to_datetime(dev['Time'],   errors='coerce')\n",
    "\n",
    "# 합치기\n",
    "behaviors = pd.concat([train, dev], ignore_index=True)\n",
    "\n",
    "# =========================\n",
    "# 2) 9,100 허용 집합(클릭 고유 뉴스) 불러오기\n",
    "# =========================\n",
    "allow_df = pd.read_csv(PATH_CLICKED_IDS)\n",
    "allowed_ids = set(str(x).strip() for x in allow_df['news_id'].tolist())\n",
    "\n",
    "# =========================\n",
    "# 3) 각 뉴스의 '최초 노출 시각' 찾기 (라벨 0/1 무관, 허용 집합에 한정)\n",
    "#    - impressions를 공백으로 나눔\n",
    "#    - \"newsId-label\"은 rsplit('-', 1)로 안전 파싱\n",
    "#    - allowed_ids에 속하는 뉴스만 고려\n",
    "#    - 가장 이른 시각을 publish_time으로 저장\n",
    "# =========================\n",
    "first_time = {}  # dict: news_id -> 가장 이른 datetime\n",
    "\n",
    "for _, row in behaviors.iterrows():\n",
    "    t = row['Time']\n",
    "    if pd.isna(t):\n",
    "        continue\n",
    "    tokens = str(row['Impressions']).split()\n",
    "    for tok in tokens:\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        news_id, _ = tok.rsplit('-', 1)\n",
    "        news_id = news_id.strip()\n",
    "\n",
    "        # 허용 집합(= 9,100) 안에서만 처리\n",
    "        if news_id not in allowed_ids:\n",
    "            continue\n",
    "\n",
    "        # 최초 등장 시각 갱신\n",
    "        if news_id not in first_time:\n",
    "            first_time[news_id] = t\n",
    "        else:\n",
    "            if t < first_time[news_id]:\n",
    "                first_time[news_id] = t\n",
    "\n",
    "# =========================\n",
    "# 4) 표로 만들고 lifespan_end = publish_time + 36시간 계산\n",
    "# =========================\n",
    "rows = []\n",
    "for nid, pub_t in first_time.items():\n",
    "    rows.append((nid, pub_t, pub_t + timedelta(hours=36)))\n",
    "\n",
    "news_lifespan_df = pd.DataFrame(rows, columns=['news_id', 'publish_time', 'lifespan_end'])\n",
    "\n",
    "# 정렬은 선택(보기 편하게)\n",
    "news_lifespan_df = news_lifespan_df.sort_values('publish_time').reset_index(drop=True)\n",
    "\n",
    "print(news_lifespan_df.head())\n",
    "print(\"총 개수:\", len(news_lifespan_df))\n",
    "\n",
    "# (참고) 허용 집합에 있었지만 behaviors에서 시간이 잡히지 않은 뉴스가 있는지 체크\n",
    "missing_ids = sorted(list(allowed_ids - set(first_time.keys())))\n",
    "print(\"허용 집합 중 publish_time을 찾지 못한 개수:\", len(missing_ids))\n",
    "# 필요하면 아래 주석 해제해서 어떤 ID들인지 확인\n",
    "# print(missing_ids[:20])\n",
    "\n",
    "# =========================\n",
    "# 5) 저장 (다음 단계에서 재사용)\n",
    "# =========================\n",
    "news_lifespan_df.to_csv(OUT_LIFESPAN, index=False)\n",
    "print(f\"저장 완료 → {OUT_LIFESPAN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7cff0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 train 행 개수: 156965\n",
      "한 행에 impression-1(클릭)이 2개 이상인 행 개수: 43077\n",
      "113888\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "# 헤더 없음 주의\n",
    "train = pd.read_csv('download/MINDsmall_train/behaviors.tsv', sep='\\t',\n",
    "                    names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "def count_pos_in_row(imps_str):\n",
    "    \"\"\"한 행의 Impressions에서 -1(클릭) 개수 세기 (초보자용 안전 파싱)\"\"\"\n",
    "    if pd.isna(imps_str):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for token in str(imps_str).split():\n",
    "        if '-' not in token:\n",
    "            continue\n",
    "        news_id, label = token.rsplit('-', 1)\n",
    "        if label.strip() == '1':\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "train['pos_cnt'] = train['Impressions'].apply(count_pos_in_row)\n",
    "\n",
    "rows_with_multi_pos = (train['pos_cnt'] >= 2).sum()\n",
    "print(\"전체 train 행 개수:\", len(train))\n",
    "print(\"한 행에 impression-1(클릭)이 2개 이상인 행 개수:\", rows_with_multi_pos)\n",
    "print(len(train)-rows_with_multi_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46d2eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== train =====\n",
      "원본 행수: 156,965  →  예상 변경 후: 236,344  (Δ +79,379)\n",
      "- Time이 NaT인 행 수: 0\n",
      "- 허용집합 기준 -1이 2개 이상인 행 수: 43,077\n",
      "- 그 행들에서의 -1 총합: 122,456\n",
      "\n",
      "[-1 개수 분포 (허용집합 기준)]\n",
      "2개 -1: 25571행\n",
      "3개 -1: 9263행\n",
      "4개 -1: 3975행\n",
      "5개 -1: 1957행\n",
      "6개 -1: 942행\n",
      "7개 -1: 515행\n",
      "8개 -1: 296행\n",
      "9개 -1: 198행\n",
      "10개 -1: 117행\n",
      "11개 -1: 81행\n",
      "12개 -1: 46행\n",
      "13개 -1: 38행\n",
      "14개 -1: 22행\n",
      "15개 -1: 17행\n",
      "16개 -1: 10행\n",
      "17개 -1: 6행\n",
      "18개 -1: 9행\n",
      "19개 -1: 2행\n",
      "20개 -1: 1행\n",
      "21개 -1: 2행\n",
      "22개 -1: 1행\n",
      "23개 -1: 1행\n",
      "24개 -1: 1행\n",
      "25개 -1: 1행\n",
      "26개 -1: 2행\n",
      "27개 -1: 1행\n",
      "31개 -1: 1행\n",
      "35개 -1: 1행\n",
      "\n",
      "===== dev =====\n",
      "원본 행수: 73,152  →  예상 변경 후: 111,383  (Δ +38,231)\n",
      "- Time이 NaT인 행 수: 0\n",
      "- 허용집합 기준 -1이 2개 이상인 행 수: 21,085\n",
      "- 그 행들에서의 -1 총합: 59,316\n",
      "\n",
      "[-1 개수 분포 (허용집합 기준)]\n",
      "2개 -1: 12707행\n",
      "3개 -1: 4443행\n",
      "4개 -1: 1911행\n",
      "5개 -1: 932행\n",
      "6개 -1: 426행\n",
      "7개 -1: 268행\n",
      "8개 -1: 166행\n",
      "9개 -1: 83행\n",
      "10개 -1: 61행\n",
      "11개 -1: 34행\n",
      "12개 -1: 17행\n",
      "13개 -1: 11행\n",
      "14개 -1: 5행\n",
      "15개 -1: 5행\n",
      "16개 -1: 6행\n",
      "17개 -1: 3행\n",
      "18개 -1: 2행\n",
      "19개 -1: 2행\n",
      "20개 -1: 1행\n",
      "21개 -1: 1행\n",
      "24개 -1: 1행\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "PATH_TRAIN_LIFE = 'train_lifespan.csv'  # ['news_id','publish_time','lifespan_end']\n",
    "PATH_DEV_LIFE   = 'dev_lifespan.csv'\n",
    "\n",
    "def count_allowed_pos(imps_str, allowed_ids):\n",
    "    \"\"\"허용 집합(=lifespan news_id) 기준으로 -1(클릭) 개수 세기\"\"\"\n",
    "    if pd.isna(imps_str):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for tok in str(imps_str).split():\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        nid, lab = tok.rsplit('-', 1)\n",
    "        if (lab.strip() == '1') and (nid.strip() in allowed_ids):\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def analyze_split(beh_path, life_path, split_name):\n",
    "    # 1) 데이터 로드 + 시간 파싱\n",
    "    df = pd.read_csv(beh_path, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "\n",
    "    # 2) 허용 집합(= 해당 split lifespan의 news_id)\n",
    "    life_df = pd.read_csv(life_path)\n",
    "    allowed_ids = set(str(x).strip() for x in life_df['news_id'].dropna().tolist())\n",
    "\n",
    "    # 3) 4단계 규칙에 맞춰 '예상 변경 후 행수'와 분포 계산\n",
    "    orig_rows = len(df)\n",
    "    new_rows = 0\n",
    "\n",
    "    rows_with_multi = 0\n",
    "    sum_pos_in_multi = 0\n",
    "    dist = {}  # {양성개수: 행 수}\n",
    "\n",
    "    rows_time_nat = 0\n",
    "    rows_with_at_least_one_allowed_pos = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        pos_cnt_allowed = count_allowed_pos(row['Impressions'], allowed_ids)\n",
    "        is_nat = pd.isna(row['Time'])\n",
    "\n",
    "        # 분포(허용 집합 기준)\n",
    "        if pos_cnt_allowed >= 2:\n",
    "            rows_with_multi += 1\n",
    "            sum_pos_in_multi += pos_cnt_allowed\n",
    "            dist[pos_cnt_allowed] = dist.get(pos_cnt_allowed, 0) + 1\n",
    "\n",
    "        # 4단계 확장 규칙과 동일하게 '예상 새 행수' 누적\n",
    "        if (not is_nat) and (pos_cnt_allowed >= 1):\n",
    "            new_rows += pos_cnt_allowed     # 양성 m개면 m행\n",
    "            rows_with_at_least_one_allowed_pos += 1\n",
    "        else:\n",
    "            new_rows += 1                   # NaT이거나 양성 0개면 1행 유지\n",
    "            if is_nat:\n",
    "                rows_time_nat += 1\n",
    "\n",
    "    delta = new_rows - orig_rows\n",
    "\n",
    "    # 4) 출력 (split 별)\n",
    "    print(f\"\\n===== {split_name} =====\")\n",
    "    print(f\"원본 행수: {orig_rows:,}  →  예상 변경 후: {new_rows:,}  (Δ {delta:+,})\")\n",
    "    print(f\"- Time이 NaT인 행 수: {rows_time_nat:,}\")\n",
    "    print(f\"- 허용집합 기준 -1이 2개 이상인 행 수: {rows_with_multi:,}\")\n",
    "    print(f\"- 그 행들에서의 -1 총합: {sum_pos_in_multi:,}\")\n",
    "\n",
    "    print(\"\\n[-1 개수 분포 (허용집합 기준)]\")\n",
    "    for k in sorted(dist):\n",
    "        print(f\"{k}개 -1: {dist[k]}행\")\n",
    "\n",
    "# 실행\n",
    "analyze_split(PATH_TRAIN, PATH_TRAIN_LIFE, 'train')\n",
    "analyze_split(PATH_DEV,   PATH_DEV_LIFE,   'dev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ebe7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[허용 집합] news_times_global: rows=9,100, allowed_ids=9,100, col='news_id'\n",
      "\n",
      "===== train : 파일 로드 =====\n",
      "- behaviors: download/MINDsmall_train/behaviors.tsv rows=156,965\n",
      "- Time NaT(파싱 실패) 건수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train] scanning: 100%|██████████| 156965/156965 [00:03<00:00, 40238.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== train : 요약 (허용집합=news_times_global) =====\n",
      "원본 행수: 156,965  →  예상 변경 후: 236,344  (Δ +79,379)\n",
      "- Time이 NaT인 행 수: 0\n",
      "- 허용집합 기준 -1이 2개 이상인 행 수: 43,077\n",
      "- 그 행들에서의 -1 총합: 122,456\n",
      "- 허용집합 기준 -1≥1 인 행 수: 156,965\n",
      "\n",
      "[-1 개수 분포 (허용집합 기준) 상위]\n",
      "2개 -1: 25571행\n",
      "3개 -1: 9263행\n",
      "4개 -1: 3975행\n",
      "5개 -1: 1957행\n",
      "6개 -1: 942행\n",
      "7개 -1: 515행\n",
      "8개 -1: 296행\n",
      "9개 -1: 198행\n",
      "10개 -1: 117행\n",
      "11개 -1: 81행\n",
      "12개 -1: 46행\n",
      "13개 -1: 38행\n",
      "14개 -1: 22행\n",
      "15개 -1: 17행\n",
      "16개 -1: 10행\n",
      "... (그 외 13개 bin)\n",
      "\n",
      "===== dev : 파일 로드 =====\n",
      "- behaviors: download/MINDsmall_dev/behaviors.tsv rows=73,152\n",
      "- Time NaT(파싱 실패) 건수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[dev] scanning: 100%|██████████| 73152/73152 [00:01<00:00, 40796.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== dev : 요약 (허용집합=news_times_global) =====\n",
      "원본 행수: 73,152  →  예상 변경 후: 111,383  (Δ +38,231)\n",
      "- Time이 NaT인 행 수: 0\n",
      "- 허용집합 기준 -1이 2개 이상인 행 수: 21,085\n",
      "- 그 행들에서의 -1 총합: 59,316\n",
      "- 허용집합 기준 -1≥1 인 행 수: 73,152\n",
      "\n",
      "[-1 개수 분포 (허용집합 기준) 상위]\n",
      "2개 -1: 12707행\n",
      "3개 -1: 4443행\n",
      "4개 -1: 1911행\n",
      "5개 -1: 932행\n",
      "6개 -1: 426행\n",
      "7개 -1: 268행\n",
      "8개 -1: 166행\n",
      "9개 -1: 83행\n",
      "10개 -1: 61행\n",
      "11개 -1: 34행\n",
      "12개 -1: 17행\n",
      "13개 -1: 11행\n",
      "14개 -1: 5행\n",
      "15개 -1: 5행\n",
      "16개 -1: 6행\n",
      "... (그 외 6개 bin)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "PATH_NEWS_GLOBAL = 'news_times_global.csv'  # 허용 news id를 한 번에 사용\n",
    "\n",
    "# =========================\n",
    "# 허용 집합: news_times_global에서 news_id 컬럼 자동 감지\n",
    "# =========================\n",
    "assert os.path.exists(PATH_NEWS_GLOBAL), f\"파일 없음: {PATH_NEWS_GLOBAL}\"\n",
    "ng = pd.read_csv(PATH_NEWS_GLOBAL, parse_dates=['publish_time','lifespan_end'])\n",
    "cand_cols = [c for c in ng.columns if c.lower() in ('news_id', 'newsid', 'nid')]\n",
    "if not cand_cols:\n",
    "    # 흔한 케이스(NewsID/news_id)도 커버\n",
    "    if 'NewsID' in ng.columns:\n",
    "        cand_cols = ['NewsID']\n",
    "    elif 'news_id' in ng.columns:\n",
    "        cand_cols = ['news_id']\n",
    "    else:\n",
    "        raise ValueError(f\"{PATH_NEWS_GLOBAL}에 news_id 컬럼이 필요합니다. 실제 컬럼: {list(ng.columns)}\")\n",
    "NEWS_COL = cand_cols[0]\n",
    "ALLOWED_IDS = set(ng[NEWS_COL].astype(str).str.strip())\n",
    "print(f\"[허용 집합] news_times_global: rows={len(ng):,}, allowed_ids={len(ALLOWED_IDS):,}, col='{NEWS_COL}'\")\n",
    "\n",
    "# =========================\n",
    "# 유틸\n",
    "# =========================\n",
    "def count_allowed_pos(imps_str, allowed_ids):\n",
    "    \"\"\"허용 집합 기준으로 -1(클릭) 개수 세기\"\"\"\n",
    "    if pd.isna(imps_str):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for tok in str(imps_str).split():\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        nid, lab = tok.rsplit('-', 1)\n",
    "        if (lab.strip() == '1') and (nid.strip() in allowed_ids):\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def analyze_split(beh_path, split_name, allowed_ids, print_top_k=15):\n",
    "    assert os.path.exists(beh_path), f\"behaviors 파일 없음: {beh_path}\"\n",
    "    df = pd.read_csv(beh_path, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "    # 로깅\n",
    "    print(f\"\\n===== {split_name} : 파일 로드 =====\")\n",
    "    print(f\"- behaviors: {beh_path} rows={len(df):,}\")\n",
    "\n",
    "    # Time 파싱\n",
    "    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "    nat_before = df['Time'].isna().sum()\n",
    "    print(f\"- Time NaT(파싱 실패) 건수: {nat_before:,}\")\n",
    "\n",
    "    # 통계\n",
    "    orig_rows = len(df)\n",
    "    new_rows = 0\n",
    "    rows_with_multi = 0\n",
    "    sum_pos_in_multi = 0\n",
    "    freq = defaultdict(int)\n",
    "    rows_time_nat = 0\n",
    "    rows_with_at_least_one_allowed_pos = 0\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"[{split_name}] scanning\"):\n",
    "        pos_cnt_allowed = count_allowed_pos(row['Impressions'], allowed_ids)\n",
    "        is_nat = pd.isna(row['Time'])\n",
    "\n",
    "        if pos_cnt_allowed >= 2:\n",
    "            rows_with_multi += 1\n",
    "            sum_pos_in_multi += pos_cnt_allowed\n",
    "            freq[pos_cnt_allowed] += 1\n",
    "\n",
    "        # 규칙: (Time 유효) & (허용집합 기준 양성>=1) → 양성 m개면 m행으로 분리\n",
    "        if (not is_nat) and (pos_cnt_allowed >= 1):\n",
    "            new_rows += pos_cnt_allowed\n",
    "            rows_with_at_least_one_allowed_pos += 1\n",
    "        else:\n",
    "            new_rows += 1\n",
    "            if is_nat:\n",
    "                rows_time_nat += 1\n",
    "\n",
    "    delta = new_rows - orig_rows\n",
    "\n",
    "    # 출력\n",
    "    print(f\"\\n===== {split_name} : 요약 (허용집합=news_times_global) =====\")\n",
    "    print(f\"원본 행수: {orig_rows:,}  →  예상 변경 후: {new_rows:,}  (Δ {delta:+,})\")\n",
    "    print(f\"- Time이 NaT인 행 수: {rows_time_nat:,}\")\n",
    "    print(f\"- 허용집합 기준 -1이 2개 이상인 행 수: {rows_with_multi:,}\")\n",
    "    print(f\"- 그 행들에서의 -1 총합: {sum_pos_in_multi:,}\")\n",
    "    print(f\"- 허용집합 기준 -1≥1 인 행 수: {rows_with_at_least_one_allowed_pos:,}\")\n",
    "\n",
    "    if freq:\n",
    "        print(\"\\n[-1 개수 분포 (허용집합 기준) 상위]\")\n",
    "        for k in sorted(freq)[:print_top_k]:\n",
    "            print(f\"{k}개 -1: {freq[k]}행\")\n",
    "        if len(freq) > print_top_k:\n",
    "            rest = len(freq) - print_top_k\n",
    "            print(f\"... (그 외 {rest}개 bin)\")\n",
    "\n",
    "# =========================\n",
    "# 실행: news_times_global 한 벌로 train/dev 동시 분석\n",
    "# =========================\n",
    "analyze_split(PATH_TRAIN, 'train', ALLOWED_IDS)\n",
    "analyze_split(PATH_DEV,   'dev',   ALLOWED_IDS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767375b",
   "metadata": {},
   "source": [
    "### 뉴스 수명 계산\n",
    "#### train/dev 분리하여 생성\n",
    "#### 뉴스 출판 시간: impression Time에서 가장 최초의 시간\n",
    "#### 뉴스 수명 시간: impression Time에서 +36시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ff05c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 허용 집합 로드: clicked_newsIds_global.csv (개수=9100)\n",
      "완료: 수명표 저장\n",
      " - train_lifespan.csv 8069\n",
      " - dev_lifespan.csv 3221\n",
      "허용 ID 중 train에 등장하지 않은 개수: 1031\n",
      "허용 ID 중 dev에 등장하지 않은 개수  : 5879\n"
     ]
    }
   ],
   "source": [
    "# A_make_lifespan_tables.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# =========================================================\n",
    "# 설정\n",
    "# =========================================================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "# 파일 경로 (필요시 수정)\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "\n",
    "# 9,100 허용 집합(클릭 고유 뉴스 ID) 파일\n",
    "PATH_CLICKED_IDS = 'clicked_newsIds_global.csv'   # (1단계 산출물, col: news_id)\n",
    "\n",
    "# 출력 파일 (split별 lifespan)\n",
    "OUT_TRAIN_LIFE = 'train_lifespan.csv'   # ['news_id','publish_time','lifespan_end']\n",
    "OUT_DEV_LIFE   = 'dev_lifespan.csv'\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 0) 보조 함수\n",
    "# =========================================================\n",
    "def build_clicked_set(df):\n",
    "    \"\"\"\n",
    "    df 전체에서 클릭(-1)된 뉴스의 고유 ID 집합을 만든다.\n",
    "    - Impressions를 공백으로 나눔\n",
    "    - \"newsId-label\"에서 label이 '1'인 것만 수집\n",
    "    - rsplit('-', 1)로 뒤에서 한 번만 분리 (안전)\n",
    "    \"\"\"\n",
    "    s = set()\n",
    "    for _, row in df.iterrows():\n",
    "        tokens = str(row['Impressions']).split()\n",
    "        for tok in tokens:\n",
    "            if '-' not in tok:\n",
    "                continue\n",
    "            nid, lbl = tok.rsplit('-', 1)\n",
    "            if lbl.strip() == '1':\n",
    "                s.add(nid.strip())\n",
    "    return s\n",
    "\n",
    "\n",
    "def build_lifespan_table(df, allowed_ids):\n",
    "    \"\"\"\n",
    "    split 하나에 대한 수명표 만들기 (허용 집합에 포함된 뉴스만):\n",
    "      - 각 뉴스ID의 '해당 split에서의 최초 등장 시각'을 publish_time으로\n",
    "      - lifespan_end = publish_time + 36시간\n",
    "      - 반환: DataFrame(columns=['news_id','publish_time','lifespan_end'])\n",
    "    \"\"\"\n",
    "    first_time = {}  # dict: news_id -> 가장 이른 datetime\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        t = row['Time']  # 이 행의 노출 시각\n",
    "        if pd.isna(t):\n",
    "            continue\n",
    "        tokens = str(row['Impressions']).split()\n",
    "        for token in tokens:\n",
    "            if '-' not in token:\n",
    "                continue\n",
    "            news_id, _ = token.rsplit('-', 1)\n",
    "            news_id = news_id.strip()\n",
    "\n",
    "            # ★ 허용 집합(9,100)에 포함된 뉴스만 대상\n",
    "            if news_id not in allowed_ids:\n",
    "                continue\n",
    "\n",
    "            # 최초 등장 시각 갱신\n",
    "            if news_id not in first_time:\n",
    "                first_time[news_id] = t\n",
    "            else:\n",
    "                if t < first_time[news_id]:\n",
    "                    first_time[news_id] = t\n",
    "\n",
    "    # 표로 변환\n",
    "    rows = []\n",
    "    for nid, pub_t in first_time.items():\n",
    "        lifespan_end = pub_t + timedelta(hours=36)\n",
    "        rows.append((nid, pub_t, lifespan_end))\n",
    "\n",
    "    life_df = pd.DataFrame(rows, columns=['news_id', 'publish_time', 'lifespan_end'])\n",
    "    return life_df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) behaviors 불러오기 (헤더 없음 주의) + 시간 파싱\n",
    "# =========================================================\n",
    "train = pd.read_csv(PATH_TRAIN, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "dev   = pd.read_csv(PATH_DEV,   sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "\n",
    "train['Time'] = pd.to_datetime(train['Time'], errors='coerce')\n",
    "dev['Time']   = pd.to_datetime(dev['Time'],   errors='coerce')\n",
    "\n",
    "# 허용 집합 파일이 없으면 즉석에서 생성 (train+dev 합쳐서 클릭 뉴스 뽑음)\n",
    "if os.path.exists(PATH_CLICKED_IDS):\n",
    "    allow_df = pd.read_csv(PATH_CLICKED_IDS)\n",
    "    allowed_ids = set(str(x).strip() for x in allow_df['news_id'].dropna().tolist())\n",
    "    print(f\"[OK] 허용 집합 로드: {PATH_CLICKED_IDS} (개수={len(allowed_ids)})\")\n",
    "else:\n",
    "    print(f\"[INFO] 허용 집합 파일 없음 → 즉석 생성: {PATH_CLICKED_IDS}\")\n",
    "    both = pd.concat([train, dev], ignore_index=True)\n",
    "    allowed_ids = build_clicked_set(both)\n",
    "    pd.DataFrame({'news_id': sorted(allowed_ids)}).to_csv(PATH_CLICKED_IDS, index=False)\n",
    "    print(f\"[OK] 생성 및 저장 완료: {PATH_CLICKED_IDS} (개수={len(allowed_ids)})\")\n",
    "\n",
    "# =========================================================\n",
    "# 2) split별 수명표 생성 & 저장 (★ train/dev 각각, 그리고 ★ 허용 집합 제한 적용)\n",
    "# =========================================================\n",
    "train_life = build_lifespan_table(train, allowed_ids)\n",
    "dev_life   = build_lifespan_table(dev,   allowed_ids)\n",
    "\n",
    "train_life.to_csv(OUT_TRAIN_LIFE, index=False)\n",
    "dev_life.to_csv(OUT_DEV_LIFE,     index=False)\n",
    "\n",
    "print(\"완료: 수명표 저장\")\n",
    "print(\" -\", OUT_TRAIN_LIFE, len(train_life))\n",
    "print(\" -\", OUT_DEV_LIFE,   len(dev_life))\n",
    "\n",
    "# (선택) 각 split에서 허용 집합 중 등장하지 않은 ID 수 체크(모니터링용)\n",
    "miss_train = len(allowed_ids - set(train_life['news_id']))\n",
    "miss_dev   = len(allowed_ids - set(dev_life['news_id']))\n",
    "print(f\"허용 ID 중 train에 등장하지 않은 개수: {miss_train}\")\n",
    "print(f\"허용 ID 중 dev에 등장하지 않은 개수  : {miss_dev}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6550bdc",
   "metadata": {},
   "source": [
    "## 뉴스 추천 데이터 behaviors 재생성\n",
    "### train/dev 데이터 분리하여 생성\n",
    "### 클릭한 뉴스가 한 행에 여러 행이 있는 경우 행 분리\n",
    "### 클릭하지 않은 뉴스는 9100개로 분리된 뉴스 중에서 해당 TIME에 수명시간이 지나지 않은것 20개 랜덤 할당\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de8b6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ImpressionID  UserID                Time  \\\n",
      "0             1  U13740 2019-11-11 09:05:58   \n",
      "1             2  U91836 2019-11-12 18:11:30   \n",
      "2             3  U73700 2019-11-14 07:01:48   \n",
      "3             4  U34670 2019-11-11 05:28:05   \n",
      "4             5   U8125 2019-11-12 16:11:21   \n",
      "\n",
      "                                             History  \\\n",
      "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
      "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
      "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
      "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
      "4                        N10078 N56514 N14904 N33740   \n",
      "\n",
      "                                         Impressions  \\\n",
      "0                                  N55689-1 N35729-0   \n",
      "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...   \n",
      "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...   \n",
      "3                N35729-0 N33632-0 N49685-1 N27581-0   \n",
      "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...   \n",
      "\n",
      "                                     Impressions_new  \n",
      "0  N12725-0 N46590-0 N7507-0 N61662-0 N2823-0 N13...  \n",
      "1  N63178-0 N17059-1 N2297-0 N39570-0 N26524-0 N5...  \n",
      "2  N18403-0 N1410-0 N23814-1 N64252-0 N48698-0 N4...  \n",
      "3  N35402-0 N22844-0 N2869-0 N21321-0 N28668-0 N5...  \n",
      "4  N34239-0 N5053-0 N45422-0 N16826-0 N8400-1 N65...  \n",
      "   ImpressionID  UserID                Time  \\\n",
      "0             1  U80234 2019-11-15 12:37:50   \n",
      "1             2  U60458 2019-11-15 07:11:50   \n",
      "2             3  U44190 2019-11-15 09:55:12   \n",
      "3             4  U87380 2019-11-15 15:12:46   \n",
      "4             5   U9444 2019-11-15 08:25:46   \n",
      "\n",
      "                                             History  \\\n",
      "0  N55189 N46039 N51741 N53234 N11276 N264 N40716...   \n",
      "1  N58715 N32109 N51180 N33438 N54827 N28488 N611...   \n",
      "2  N56253 N1150 N55189 N16233 N61704 N51706 N5303...   \n",
      "3  N63554 N49153 N28678 N23232 N43369 N58518 N444...   \n",
      "4                 N51692 N18285 N26015 N22679 N55556   \n",
      "\n",
      "                                         Impressions  \\\n",
      "0  N28682-0 N48740-0 N31958-1 N34130-0 N6916-0 N5...   \n",
      "1  N20036-0 N23513-1 N32536-0 N46976-0 N35216-0 N...   \n",
      "2  N36779-0 N62365-0 N58098-0 N5472-0 N13408-0 N5...   \n",
      "3  N6950-0 N60215-0 N6074-0 N11930-0 N6916-0 N248...   \n",
      "4  N5940-1 N23513-0 N49285-0 N23355-0 N19990-0 N3...   \n",
      "\n",
      "                                     Impressions_new  \n",
      "0  N17659-0 N25315-0 N56133-0 N31958-1 N31179-0 N...  \n",
      "1  N21519-0 N30290-0 N614-0 N9040-0 N62001-0 N551...  \n",
      "2  N40194-0 N13464-0 N53515-0 N23855-0 N21196-0 N...  \n",
      "3  N23547-0 N50645-0 N31469-0 N3318-0 N64802-0 N3...  \n",
      "4  N8353-0 N46901-0 N5940-1 N9420-0 N16931-0 N227...  \n",
      "\n",
      "===== 행 개수 비교 =====\n",
      "train  | 원본: 156,965  →  변경 후: 236,344  (Δ +79,379)\n",
      "dev    | 원본: 73,152    →  변경 후: 111,383    (Δ +38,231)\n"
     ]
    }
   ],
   "source": [
    "# # lifespan을 train dev 나눠서 진행\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# from datetime import timedelta\n",
    "\n",
    "# random.seed(42)  # 무작위 샘플 재현용 시드\n",
    "\n",
    "# # =========================================================\n",
    "# # 설정\n",
    "# # =========================================================\n",
    "# BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "\n",
    "# # 파일 경로 (필요 시 수정)\n",
    "# PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "# PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "\n",
    "# # (A 단계에서 미리 만든 수명표 파일들: ★ 9,100 허용 집합만 포함되어 있어야 함)\n",
    "# PATH_TRAIN_LIFE = 'train_lifespan.csv'  # ['news_id','publish_time','lifespan_end']\n",
    "# PATH_DEV_LIFE   = 'dev_lifespan.csv'\n",
    "\n",
    "# K_NEG = 20  # 음성 개수 (한 행당: 양성 1 + 음성 K_NEG)\n",
    "# SHUFFLE_IMPRESSIONS = True\n",
    "\n",
    "# # =========================================================\n",
    "# # 공용 보조 함수들 (초보자 스타일)\n",
    "# # =========================================================\n",
    "# def get_all_positives(imps_str):\n",
    "#     \"\"\"\n",
    "#     Impressions 문자열에서 -1(클릭)인 모든 뉴스ID 리스트를 반환.\n",
    "#     예: \"N1-0 N2-1 N3-1 N4-0\" -> [\"N2\", \"N3\"]\n",
    "#     클릭이 하나도 없으면 [] 반환.\n",
    "#     \"\"\"\n",
    "#     result = []\n",
    "#     if pd.isna(imps_str):\n",
    "#         return result\n",
    "#     tokens = str(imps_str).split()\n",
    "#     for token in tokens:\n",
    "#         if '-' not in token:\n",
    "#             continue\n",
    "#         news_id, label = token.rsplit('-', 1)\n",
    "#         if label.strip() == '1':  # ★ 꼭 -1 인 것만 양성\n",
    "#             result.append(news_id.strip())\n",
    "#     return result\n",
    "\n",
    "# def floor_to_hour(dt):\n",
    "#     \"\"\"\n",
    "#     datetime을 '정시'로 내림.\n",
    "#     예: 2020-06-14 13:27 -> 2020-06-14 13:00\n",
    "#     \"\"\"\n",
    "#     if pd.isna(dt):\n",
    "#         return None\n",
    "#     return dt.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "# def build_user_clicked(df):\n",
    "#     \"\"\"\n",
    "#     df 전체를 훑어 사용자별 '과거/미래 포함, 한 번이라도 클릭(-1)한 뉴스ID' 집합 생성.\n",
    "#     반환: dict { user_id: set(news_id) }\n",
    "#     \"\"\"\n",
    "#     user_clicked = {}\n",
    "#     for _, row in df.iterrows():\n",
    "#         uid = row['UserID']\n",
    "#         tokens = str(row['Impressions']).split()\n",
    "#         for token in tokens:\n",
    "#             if '-' not in token:\n",
    "#                 continue\n",
    "#             news_id, label = token.rsplit('-', 1)\n",
    "#             if label.strip() == '1':\n",
    "#                 if uid not in user_clicked:\n",
    "#                     user_clicked[uid] = set()\n",
    "#                 user_clicked[uid].add(news_id.strip())\n",
    "#     return user_clicked\n",
    "\n",
    "# def build_alive_buckets_and_map(life_df):\n",
    "#     \"\"\"\n",
    "#     시간 버킷(정시 단위) → 그 시간에 '살아있는' 뉴스ID 리스트를 빠르게 얻기 위한 사전 구성.\n",
    "#     또한 정확한 분 단위 판정을 위해 news_id -> (publish_time, lifespan_end) map도 함께 생성.\n",
    "\n",
    "#     buckets: dict { hour_dt: [news_id, ...] }\n",
    "#     life_map: dict { news_id: (publish_time, lifespan_end) }\n",
    "#     \"\"\"\n",
    "#     buckets = {}\n",
    "#     life_map = {}\n",
    "\n",
    "#     for _, row in life_df.iterrows():\n",
    "#         nid   = str(row['news_id'])\n",
    "#         start = row['publish_time']\n",
    "#         end   = row['lifespan_end']\n",
    "#         life_map[nid] = (start, end)\n",
    "\n",
    "#         if pd.isna(start) or pd.isna(end):\n",
    "#             continue\n",
    "\n",
    "#         cur = floor_to_hour(start)\n",
    "#         # cur 가 end 이전까지만(행 기준 조건: row_time < lifespan_end)\n",
    "#         while cur < end:\n",
    "#             if cur not in buckets:\n",
    "#                 buckets[cur] = []\n",
    "#             buckets[cur].append(nid)\n",
    "#             cur = cur + timedelta(hours=1)\n",
    "\n",
    "#     return buckets, life_map\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # split 하나를 처리: 다중 양성 행 → '양성 개수만큼 행 확장' + 음성 샘플링\n",
    "# #  - ★ 양성도 lifespan(= 허용 집합) 안에 있는 뉴스만 사용하도록 필터링\n",
    "# #  - 음성은 lifespan 버킷에서 선택(= 허용 집합 내부) + 유저 과거/미래 미클릭 + HISTORY 미포함 + 양성과 비중복\n",
    "# # =========================================================\n",
    "# def rebuild_for_split_with_expand(beh_path, life_path, k_neg):\n",
    "#     # 1) behaviors 불러오기 (헤더 없음)\n",
    "#     df = pd.read_csv(beh_path, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "#     df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "\n",
    "#     # 2) 수명표 로드 + 버킷/맵 생성\n",
    "#     life_df = pd.read_csv(life_path, parse_dates=['publish_time','lifespan_end'])\n",
    "#     alive_buckets, life_map = build_alive_buckets_and_map(life_df)\n",
    "\n",
    "#     # 3) 사용자별 '클릭했던 뉴스 집합' (해당 split 전체 기준)\n",
    "#     u_clicked = build_user_clicked(df)\n",
    "\n",
    "#     # 4) 결과를 담을 '확장된 행' 리스트\n",
    "#     expanded_rows = []\n",
    "\n",
    "#     # 5) 각 원본 행을 순회\n",
    "#     for _, row in df.iterrows():\n",
    "#         row_time = row['Time']\n",
    "#         uid      = row['UserID']\n",
    "#         original = row['Impressions']\n",
    "\n",
    "#         # (a) 이 행의 모든 양성 뉴스ID 수집\n",
    "#         pos_list_all = get_all_positives(original)\n",
    "#         # (a-1) ★ 양성도 허용 집합(= life_map 키) 안의 뉴스만 사용\n",
    "#         allowed_pos = []\n",
    "#         for nid in pos_list_all:\n",
    "#             if nid in life_map:\n",
    "#                 allowed_pos.append(nid)\n",
    "\n",
    "#         # (b) 양성이 하나도 없거나 시간 파싱 실패라면 → 원본 그 상태로 1행만 유지\n",
    "#         if (len(allowed_pos) == 0) or pd.isna(row_time):\n",
    "#             new_row = {\n",
    "#                 'ImpressionID': row['ImpressionID'],\n",
    "#                 'UserID': row['UserID'],\n",
    "#                 'Time': row['Time'],\n",
    "#                 'History': row['History'],\n",
    "#                 'Impressions': row['Impressions'],\n",
    "#                 'Impressions_new': row['Impressions']  # 그대로 둠(원하면 \"\"로 비울 수도 있음)\n",
    "#             }\n",
    "#             expanded_rows.append(new_row)\n",
    "#             continue\n",
    "\n",
    "#         # (c) 양성이 여러 개인 경우 → '양성 1개당 1행'씩 복제 생성\n",
    "#         hour_key = floor_to_hour(row_time)\n",
    "#         candidate_ids_bucket = []\n",
    "#         if (hour_key is not None) and (hour_key in alive_buckets):\n",
    "#             candidate_ids_bucket = alive_buckets[hour_key][:]\n",
    "#         # 중복 제거\n",
    "#         candidate_ids_bucket = list(set(candidate_ids_bucket))\n",
    "\n",
    "#         # History set 준비\n",
    "#         history_set = set()\n",
    "#         if pd.notna(row['History']):\n",
    "#             for nid in str(row['History']).split():\n",
    "#                 history_set.add(nid)\n",
    "\n",
    "#         # pos마다 한 행 생성\n",
    "#         for pos_news in allowed_pos:\n",
    "#             # 1) 후보 시작: 버킷에서 꺼낸 리스트 → 정밀 시간조건으로 다시 필터링\n",
    "#             precise_candidates = []\n",
    "#             for nid in candidate_ids_bucket:\n",
    "#                 pub_t, end_t = life_map.get(nid, (None, None))\n",
    "#                 if (pub_t is None) or (end_t is None):\n",
    "#                     continue\n",
    "#                 if (pub_t <= row_time) and (row_time < end_t):\n",
    "#                     precise_candidates.append(nid)\n",
    "\n",
    "#             # 2) 사용자 과거/미래 클릭 제외\n",
    "#             clicked_set = u_clicked.get(uid, set())\n",
    "#             tmp = []\n",
    "#             for nid in precise_candidates:\n",
    "#                 if nid not in clicked_set:\n",
    "#                     tmp.append(nid)\n",
    "#             precise_candidates = tmp\n",
    "\n",
    "#             # 3) History 제외\n",
    "#             tmp = []\n",
    "#             for nid in precise_candidates:\n",
    "#                 if nid not in history_set:\n",
    "#                     tmp.append(nid)\n",
    "#             precise_candidates = tmp\n",
    "\n",
    "#             # 4) 양성과 중복 금지\n",
    "#             tmp = []\n",
    "#             for nid in precise_candidates:\n",
    "#                 if nid != pos_news:\n",
    "#                     tmp.append(nid)\n",
    "#             precise_candidates = tmp\n",
    "\n",
    "#             # 5) 음성 무작위 추출 (부족하면 있는 만큼만)\n",
    "#             if len(precise_candidates) >= k_neg:\n",
    "#                 neg_news = random.sample(precise_candidates, k_neg)\n",
    "#             else:\n",
    "#                 neg_news = precise_candidates\n",
    "\n",
    "#             # 6) 최종 Impressions 문자열 (양성 -1, 음성 -0)\n",
    "#             parts = [f\"{pos_news}-1\"]\n",
    "#             for nid in neg_news:\n",
    "#                 parts.append(f\"{nid}-0\")\n",
    "#             if SHUFFLE_IMPRESSIONS:\n",
    "#                 random.shuffle(parts)\n",
    "#             new_imps_str = \" \".join(parts)\n",
    "\n",
    "#             # 7) 원본 행을 복제하되, Impressions_new만 다르게 설정\n",
    "#             new_row = {\n",
    "#                 'ImpressionID': row['ImpressionID'],   # ★ 동일 ID 유지(필요시 새 ID 부여 가능)\n",
    "#                 'UserID': row['UserID'],\n",
    "#                 'Time': row['Time'],\n",
    "#                 'History': row['History'],\n",
    "#                 'Impressions': row['Impressions'],\n",
    "#                 'Impressions_new': new_imps_str\n",
    "#             }\n",
    "#             expanded_rows.append(new_row)\n",
    "\n",
    "#     # 6) 확장된 행들로 DataFrame 생성 (원본 5컬럼 + Impressions_new)\n",
    "#     out_df = pd.DataFrame(expanded_rows, columns=BEHAVIOR_COLUMNS + ['Impressions_new'])\n",
    "#     return df, out_df   # 원본 df도 함께 반환하여 개수 비교에 사용\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # 실행: train/dev 각각 처리 + 행 개수 비교 출력\n",
    "# # =========================================================\n",
    "# # train\n",
    "# train_orig_df, train_final = rebuild_for_split_with_expand(PATH_TRAIN, PATH_TRAIN_LIFE, K_NEG)\n",
    "# # dev\n",
    "# dev_orig_df,   dev_final   = rebuild_for_split_with_expand(PATH_DEV,   PATH_DEV_LIFE,   K_NEG)\n",
    "\n",
    "# # --- 결과 미리보기\n",
    "# print(train_final.head())\n",
    "# print(dev_final.head())\n",
    "\n",
    "# # --- 행 개수 비교 출력\n",
    "# orig_train_rows = len(train_orig_df)\n",
    "# orig_dev_rows   = len(dev_orig_df)\n",
    "# new_train_rows  = len(train_final)\n",
    "# new_dev_rows    = len(dev_final)\n",
    "\n",
    "# print(\"\\n===== 행 개수 비교 =====\")\n",
    "# print(f\"train  | 원본: {orig_train_rows:,}  →  변경 후: {new_train_rows:,}  (Δ {new_train_rows - orig_train_rows:+,})\")\n",
    "# print(f\"dev    | 원본: {orig_dev_rows:,}    →  변경 후: {new_dev_rows:,}    (Δ {new_dev_rows - orig_dev_rows:+,})\")\n",
    "\n",
    "# # (선택) 저장\n",
    "# train_final.to_csv('train_expanded_global.tsv', sep='\\t', index=False)\n",
    "# dev_final.to_csv('dev_expanded_global.tsv',   sep='\\t', index=False)\n",
    "\n",
    "# # (선택) 학습 포맷(5컬럼)으로 쓰려면, Impressions ← Impressions_new 교체 + 5컬럼만:\n",
    "# train_out = train_final.copy()\n",
    "# train_out['Impressions'] = train_out['Impressions_new']\n",
    "# train_out = train_out[BEHAVIOR_COLUMNS]\n",
    "# train_out.to_csv('train_rebuilt_expanded_global.tsv', sep='\\t', header=False, index=False)\n",
    "\n",
    "# dev_out = dev_final.copy()\n",
    "# dev_out['Impressions'] = dev_out['Impressions_new']\n",
    "# dev_out = dev_out[BEHAVIOR_COLUMNS]\n",
    "# dev_out.to_csv('dev_rebuilt_expanded_global.tsv', sep='\\t', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a8962b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OriginalImpressionID  ImpressionID  UserID                Time  \\\n",
      "0                     1             1  U13740 2019-11-11 09:05:58   \n",
      "1                     2             2  U91836 2019-11-12 18:11:30   \n",
      "2                     3             3  U73700 2019-11-14 07:01:48   \n",
      "3                     4             4  U34670 2019-11-11 05:28:05   \n",
      "4                     5             5   U8125 2019-11-12 16:11:21   \n",
      "\n",
      "                                             History  \\\n",
      "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
      "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
      "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
      "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
      "4                        N10078 N56514 N14904 N33740   \n",
      "\n",
      "                                         Impressions  \\\n",
      "0                                  N55689-1 N35729-0   \n",
      "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...   \n",
      "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...   \n",
      "3                N35729-0 N33632-0 N49685-1 N27581-0   \n",
      "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...   \n",
      "\n",
      "                                     Impressions_new  \n",
      "0  N12725-0 N46590-0 N7507-0 N61662-0 N2823-0 N13...  \n",
      "1  N63178-0 N17059-1 N2297-0 N39570-0 N26524-0 N5...  \n",
      "2  N18403-0 N1410-0 N23814-1 N64252-0 N48698-0 N4...  \n",
      "3  N35402-0 N22844-0 N2869-0 N21321-0 N28668-0 N5...  \n",
      "4  N34239-0 N5053-0 N39356-0 N16826-0 N8400-1 N48...  \n",
      "   OriginalImpressionID  ImpressionID  UserID                Time  \\\n",
      "0                     1             1  U80234 2019-11-15 12:37:50   \n",
      "1                     2             2  U60458 2019-11-15 07:11:50   \n",
      "2                     3             3  U44190 2019-11-15 09:55:12   \n",
      "3                     4             4  U87380 2019-11-15 15:12:46   \n",
      "4                     5             5   U9444 2019-11-15 08:25:46   \n",
      "\n",
      "                                             History  \\\n",
      "0  N55189 N46039 N51741 N53234 N11276 N264 N40716...   \n",
      "1  N58715 N32109 N51180 N33438 N54827 N28488 N611...   \n",
      "2  N56253 N1150 N55189 N16233 N61704 N51706 N5303...   \n",
      "3  N63554 N49153 N28678 N23232 N43369 N58518 N444...   \n",
      "4                 N51692 N18285 N26015 N22679 N55556   \n",
      "\n",
      "                                         Impressions  \\\n",
      "0  N28682-0 N48740-0 N31958-1 N34130-0 N6916-0 N5...   \n",
      "1  N20036-0 N23513-1 N32536-0 N46976-0 N35216-0 N...   \n",
      "2  N36779-0 N62365-0 N58098-0 N5472-0 N13408-0 N5...   \n",
      "3  N6950-0 N60215-0 N6074-0 N11930-0 N6916-0 N248...   \n",
      "4  N5940-1 N23513-0 N49285-0 N23355-0 N19990-0 N3...   \n",
      "\n",
      "                                     Impressions_new  \n",
      "0  N46885-0 N33176-0 N46338-0 N31958-1 N29133-0 N...  \n",
      "1  N43715-0 N3972-0 N36404-0 N27063-0 N31799-0 N6...  \n",
      "2  N32734-0 N22346-0 N29534-0 N58748-0 N9217-0 N2...  \n",
      "3  N2636-0 N53283-0 N1443-0 N24826-0 N17405-0 N62...  \n",
      "4  N5940-1 N6642-0 N28477-0 N48707-0 N53283-0 N61...  \n",
      "\n",
      "===== 행 개수 비교 =====\n",
      "train | 원본: 156,965  →  변경 후: 236,344  (Δ +79,379)\n",
      "dev   | 원본: 73,152    →  변경 후: 111,383    (Δ +38,231)\n"
     ]
    }
   ],
   "source": [
    "# lifespan이 global\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import timedelta\n",
    "\n",
    "random.seed(42)  # 재현성\n",
    "\n",
    "# =========================\n",
    "# 설정\n",
    "# =========================\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID', 'UserID', 'Time', 'History', 'Impressions']\n",
    "PATH_TRAIN = 'download/MINDsmall_train/behaviors.tsv'\n",
    "PATH_DEV   = 'download/MINDsmall_dev/behaviors.tsv'\n",
    "\n",
    "# 전역 허용집합 / 전역 lifespan 파일\n",
    "PATH_CLICKED_GLOBAL = 'clicked_newsIds_global.csv'   # col: news_id\n",
    "PATH_LIFE_GLOBAL    = 'news_times_global.csv'        # col: news_id, publish_time, lifespan_end\n",
    "\n",
    "K_NEG = 20\n",
    "SHUFFLE_IMPRESSIONS = True\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 보조 함수\n",
    "# =========================\n",
    "def get_all_positives(imps_str):\n",
    "    out = []\n",
    "    if pd.isna(imps_str):\n",
    "        return out\n",
    "    for tok in str(imps_str).split():\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        nid, lab = tok.rsplit('-', 1)\n",
    "        if lab.strip() == '1':\n",
    "            out.append(nid.strip())\n",
    "    return out\n",
    "\n",
    "def floor_to_hour(dt):\n",
    "    if pd.isna(dt):\n",
    "        return None\n",
    "    return dt.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "def build_user_clicked(df):\n",
    "    m = {}\n",
    "    for _, row in df.iterrows():\n",
    "        uid = row['UserID']\n",
    "        for tok in str(row['Impressions']).split():\n",
    "            if '-' not in tok:\n",
    "                continue\n",
    "            nid, lab = tok.rsplit('-', 1)\n",
    "            if lab.strip() == '1':\n",
    "                m.setdefault(uid, set()).add(nid.strip())\n",
    "    return m\n",
    "\n",
    "def build_clicked_set(df):\n",
    "    s = set()\n",
    "    for _, row in df.iterrows():\n",
    "        for tok in str(row['Impressions']).split():\n",
    "            if '-' not in tok:\n",
    "                continue\n",
    "            nid, lab = tok.rsplit('-', 1)\n",
    "            if lab.strip() == '1':\n",
    "                s.add(nid.strip())\n",
    "    return s\n",
    "\n",
    "def build_global_lifespan(behaviors_df, allowed_ids):\n",
    "    # 각 뉴스의 \"전역 최초 노출 시각\"을 publish_time으로, +36h\n",
    "    first_time = {}\n",
    "    for _, row in behaviors_df.iterrows():\n",
    "        t = row['Time']\n",
    "        if pd.isna(t):\n",
    "            continue\n",
    "        for tok in str(row['Impressions']).split():\n",
    "            if '-' not in tok:\n",
    "                continue\n",
    "            nid, _ = tok.rsplit('-', 1)\n",
    "            nid = nid.strip()\n",
    "            if nid not in allowed_ids:\n",
    "                continue\n",
    "            if nid not in first_time or t < first_time[nid]:\n",
    "                first_time[nid] = t\n",
    "    rows = []\n",
    "    for nid, pub in first_time.items():\n",
    "        rows.append((nid, pub, pub + timedelta(hours=36)))\n",
    "    life = pd.DataFrame(rows, columns=['news_id','publish_time','lifespan_end'])\n",
    "    life = life.sort_values('publish_time').reset_index(drop=True)\n",
    "    return life\n",
    "\n",
    "def build_alive_buckets_and_map(life_df):\n",
    "    buckets = {}\n",
    "    life_map = {}\n",
    "    for _, r in life_df.iterrows():\n",
    "        nid   = str(r['news_id']).strip()\n",
    "        start = r['publish_time']\n",
    "        end   = r['lifespan_end']\n",
    "        life_map[nid] = (start, end)\n",
    "        if pd.isna(start) or pd.isna(end):\n",
    "            continue\n",
    "        cur = floor_to_hour(start)\n",
    "        while cur < end:\n",
    "            buckets.setdefault(cur, []).append(nid)\n",
    "            cur = cur + timedelta(hours=1)\n",
    "    return buckets, life_map\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 전역 허용집합 / 전역 lifespan 준비\n",
    "# =========================\n",
    "# train/dev 로드 + 시간 파싱\n",
    "train = pd.read_csv(PATH_TRAIN, sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "dev   = pd.read_csv(PATH_DEV,   sep='\\t', names=BEHAVIOR_COLUMNS, header=None)\n",
    "train['Time'] = pd.to_datetime(train['Time'], errors='coerce')\n",
    "dev['Time']   = pd.to_datetime(dev['Time'],   errors='coerce')\n",
    "\n",
    "both = pd.concat([train, dev], ignore_index=True)\n",
    "\n",
    "# 전역 허용집합\n",
    "if os.path.exists(PATH_CLICKED_GLOBAL):\n",
    "    allow_df = pd.read_csv(PATH_CLICKED_GLOBAL)\n",
    "    allowed_ids = set(allow_df['news_id'].astype(str).str.strip())\n",
    "else:\n",
    "    allowed_ids = build_clicked_set(both)\n",
    "    pd.DataFrame({'news_id': sorted(allowed_ids)}).to_csv(PATH_CLICKED_GLOBAL, index=False)\n",
    "\n",
    "# 전역 lifespan\n",
    "if os.path.exists(PATH_LIFE_GLOBAL):\n",
    "    life_global = pd.read_csv(PATH_LIFE_GLOBAL, parse_dates=['publish_time','lifespan_end'])\n",
    "else:\n",
    "    life_global = build_global_lifespan(both, allowed_ids)\n",
    "    life_global.to_csv(PATH_LIFE_GLOBAL, index=False)\n",
    "\n",
    "# 전역 버킷/맵 (train/dev 모두 이걸 사용)\n",
    "alive_buckets_global, life_map_global = build_alive_buckets_and_map(life_global)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 재구성 함수 (전역 lifespan 사용)\n",
    "# =========================\n",
    "def rebuild_with_global_life(df_split, k_neg):\n",
    "    u_clicked = build_user_clicked(df_split)\n",
    "    expanded_rows = []\n",
    "\n",
    "    for _, row in df_split.iterrows():\n",
    "        row_time = row['Time']\n",
    "        uid      = row['UserID']\n",
    "        original = row['Impressions']\n",
    "\n",
    "        # 양성 후보: 전역 허용집합(= life_map_global 키) 안에서만\n",
    "        pos_all = get_all_positives(original)\n",
    "        allowed_pos = [nid for nid in pos_all if nid in life_map_global]\n",
    "\n",
    "        # 양성 없거나 Time NaT -> 원본 유지\n",
    "        if (len(allowed_pos) == 0) or pd.isna(row_time):\n",
    "            expanded_rows.append({\n",
    "                'ImpressionID': row['ImpressionID'],\n",
    "                'UserID': row['UserID'],\n",
    "                'Time': row['Time'],\n",
    "                'History': row['History'],\n",
    "                'Impressions': row['Impressions'],\n",
    "                'Impressions_new': row['Impressions']\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 시간 버킷 후보(전역)\n",
    "        hour_key = floor_to_hour(row_time)\n",
    "        bucket = list(set(alive_buckets_global.get(hour_key, [])))  # 중복 제거\n",
    "\n",
    "        # HISTORY set\n",
    "        history_set = set(str(row['History']).split()) if pd.notna(row['History']) else set()\n",
    "\n",
    "        for pos_news in allowed_pos:\n",
    "            # 음성 후보: alive(정밀) → 미클릭 → 미히스토리 → 양성과 비중복\n",
    "            precise = []\n",
    "            for nid in bucket:\n",
    "                pub, end = life_map_global.get(nid, (None, None))\n",
    "                if (pub is not None) and (end is not None) and (pub <= row_time < end):\n",
    "                    precise.append(nid)\n",
    "\n",
    "            clicked_set = u_clicked.get(uid, set())\n",
    "            tmp = []\n",
    "            for nid in precise:\n",
    "                if (nid not in clicked_set) and (nid not in history_set) and (nid != pos_news):\n",
    "                    tmp.append(nid)\n",
    "            precise = tmp\n",
    "\n",
    "            if len(precise) >= k_neg:\n",
    "                neg_news = random.sample(precise, k_neg)\n",
    "            else:\n",
    "                neg_news = precise\n",
    "\n",
    "            parts = [f\"{pos_news}-1\"] + [f\"{nid}-0\" for nid in neg_news]\n",
    "            if SHUFFLE_IMPRESSIONS:\n",
    "                random.shuffle(parts)\n",
    "            new_imps = \" \".join(parts)\n",
    "\n",
    "            expanded_rows.append({\n",
    "                'ImpressionID': row['ImpressionID'],\n",
    "                'UserID': row['UserID'],\n",
    "                'Time': row['Time'],\n",
    "                'History': row['History'],\n",
    "                'Impressions': row['Impressions'],\n",
    "                'Impressions_new': new_imps\n",
    "            })\n",
    "\n",
    "    out = pd.DataFrame(expanded_rows, columns=BEHAVIOR_COLUMNS + ['Impressions_new'])\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 실행: train/dev 각각 전역 lifespan으로 재구성 + 행수 비교\n",
    "# =========================\n",
    "train_final = rebuild_with_global_life(train, K_NEG)\n",
    "dev_final   = rebuild_with_global_life(dev,   K_NEG)\n",
    "\n",
    "for name, df in ((\"train\", train_final), (\"dev\", dev_final)):\n",
    "    # 원본 ID를 보존(추적용)\n",
    "    df.insert(0, 'OriginalImpressionID', df['ImpressionID'])\n",
    "    # 새 ID 부여: 1..len(df)\n",
    "    df['ImpressionID'] = range(1, len(df) + 1)\n",
    "\n",
    "print(train_final.head())\n",
    "print(dev_final.head())\n",
    "\n",
    "print(\"\\n===== 행 개수 비교 =====\")\n",
    "print(f\"train | 원본: {len(train):,}  →  변경 후: {len(train_final):,}  (Δ {len(train_final) - len(train):+,})\")\n",
    "print(f\"dev   | 원본: {len(dev):,}    →  변경 후: {len(dev_final):,}    (Δ {len(dev_final) - len(dev):+,})\")\n",
    "\n",
    "# 저장 (필요 시)\n",
    "train_final.to_csv('train_expanded_global.tsv', sep='\\t', index=False)\n",
    "dev_final.to_csv('dev_expanded_global.tsv',   sep='\\t', index=False)\n",
    "\n",
    "# 2) 학습용(5컬럼)으로 저장: Impressions <- Impressions_new 치환 후 BEHAVIOR_COLUMNS만\n",
    "def to_training_5col(df, out_path):\n",
    "    out = df.copy()\n",
    "    out['Impressions'] = out['Impressions_new']\n",
    "    out = out[['ImpressionID','UserID','Time','History','Impressions']]\n",
    "    # 모델 호환을 위해 header=False\n",
    "    out.to_csv(out_path, sep='\\t', header=False, index=False)\n",
    "\n",
    "to_training_5col(train_final, 'train_rebuilt_expanded_global.tsv')\n",
    "to_training_5col(dev_final,   'dev_rebuilt_expanded_global.tsv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b02b66",
   "metadata": {},
   "source": [
    "# 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3516f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BEHAVIOR_COLUMNS = ['ImpressionID','UserID','Time','History','Impressions']\n",
    "K_NEG = 20\n",
    "\n",
    "# -------------------------------------------\n",
    "# 유틸: impressions 문자열 파싱 (초보자 안전 버전)\n",
    "# -------------------------------------------\n",
    "def parse_imps(imps_str):\n",
    "    \"\"\"\n",
    "    'newsid-label' 토큰들로 분할하여 [(nid, lab), ...] 리스트 반환\n",
    "    lab은 '0' 또는 '1'만 유효로 간주\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    if pd.isna(imps_str):\n",
    "        return out\n",
    "    for tok in str(imps_str).split():\n",
    "        if '-' not in tok:\n",
    "            continue\n",
    "        nid, lab = tok.rsplit('-', 1)\n",
    "        nid = nid.strip()\n",
    "        lab = lab.strip()\n",
    "        if lab in ('0','1'):\n",
    "            out.append((nid, lab))\n",
    "    return out\n",
    "\n",
    "# -------------------------------------------\n",
    "# 핵심 검증 함수 (split 하나)\n",
    "# -------------------------------------------\n",
    "def validate_split(final_df, life_path, split_name=\"split\", k_neg=20, max_show=5):\n",
    "    \"\"\"\n",
    "    final_df: 최종 산출 DF (원본 5컬럼 + Impressions_new)\n",
    "    life_path: lifespan csv 경로 (['news_id','publish_time','lifespan_end'])\n",
    "    \"\"\"\n",
    "    print(f\"\\n===== 검증 시작: {split_name} =====\")\n",
    "\n",
    "    # 0) 준비: 시간 파싱, 허용 집합, life_map\n",
    "    df = final_df.copy()\n",
    "    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "\n",
    "    life_df = pd.read_csv(life_path, parse_dates=['publish_time','lifespan_end'])\n",
    "    allowed = set(life_df['news_id'].astype(str).str.strip())\n",
    "    life_map = {}\n",
    "    for _, r in life_df.iterrows():\n",
    "        life_map[str(r['news_id']).strip()] = (r['publish_time'], r['lifespan_end'])\n",
    "\n",
    "    # 1) 통계 카운터\n",
    "    total_rows = len(df)\n",
    "    viol_not_allowed = 0\n",
    "    viol_not_allowed_examples = []\n",
    "\n",
    "    viol_poscount = 0\n",
    "    viol_poscount_examples = []\n",
    "\n",
    "    viol_negcount = 0\n",
    "    viol_negcount_examples = []\n",
    "\n",
    "    viol_neg_lifespan = 0\n",
    "    viol_neg_lifespan_examples = []\n",
    "\n",
    "    # (옵션) 양성 alive 체크\n",
    "    viol_pos_lifespan = 0\n",
    "    viol_pos_lifespan_examples = []\n",
    "\n",
    "    # (보너스) 중복 뉴스ID 체크\n",
    "    viol_dup_ids = 0\n",
    "    viol_dup_ids_examples = []\n",
    "\n",
    "    # 2) 행별 점검\n",
    "    for idx, row in df.iterrows():\n",
    "        t = row['Time']\n",
    "        tokens = parse_imps(row['Impressions_new'])\n",
    "\n",
    "        # 2-1) 허용 집합(= 9,100) 내부인지\n",
    "        news_ids = [nid for nid, _ in tokens]\n",
    "        not_allowed = [nid for nid in news_ids if nid not in allowed]\n",
    "        if len(not_allowed) > 0:\n",
    "            viol_not_allowed += 1\n",
    "            if len(viol_not_allowed_examples) < max_show:\n",
    "                viol_not_allowed_examples.append((idx, not_allowed[:5]))\n",
    "\n",
    "        # 2-2) 양성/음성 개수\n",
    "        pos_cnt = sum(1 for _, lab in tokens if lab == '1')\n",
    "        neg_cnt = sum(1 for _, lab in tokens if lab == '0')\n",
    "\n",
    "        if pos_cnt != 1:\n",
    "            viol_poscount += 1\n",
    "            if len(viol_poscount_examples) < max_show:\n",
    "                viol_poscount_examples.append((idx, pos_cnt, row['Impressions_new']))\n",
    "\n",
    "        # 후보 부족이면 20 미만일 수 있음 → 그래도 통계로 확인\n",
    "        # (원칙: 정상 행은 neg_cnt == k_neg)\n",
    "        if (pos_cnt == 1) and (neg_cnt != k_neg):\n",
    "            viol_negcount += 1\n",
    "            if len(viol_negcount_examples) < max_show:\n",
    "                viol_negcount_examples.append((idx, neg_cnt, row['Impressions_new']))\n",
    "\n",
    "        # 2-3) lifespan 조건(음성): publish ≤ Time < lifespan_end\n",
    "        #  (t가 NaT면 이미 확장 안 했을 가능성이 큼. 그래도 방어적으로 검사)\n",
    "        bad_neg = False\n",
    "        for nid, lab in tokens:\n",
    "            if lab != '0':\n",
    "                continue\n",
    "            if nid not in life_map or pd.isna(t):\n",
    "                bad_neg = True\n",
    "                break\n",
    "            pub, end = life_map[nid]\n",
    "            if pd.isna(pub) or pd.isna(end) or not (pub <= t < end):\n",
    "                bad_neg = True\n",
    "                break\n",
    "        if bad_neg:\n",
    "            viol_neg_lifespan += 1\n",
    "            if len(viol_neg_lifespan_examples) < max_show:\n",
    "                viol_neg_lifespan_examples.append((idx, row['Time'], row['Impressions_new']))\n",
    "\n",
    "        # 2-4) (옵션) 양성 alive 확인\n",
    "        bad_pos = False\n",
    "        for nid, lab in tokens:\n",
    "            if lab != '1':\n",
    "                continue\n",
    "            if nid not in life_map or pd.isna(t):\n",
    "                bad_pos = True\n",
    "                break\n",
    "            pub, end = life_map[nid]\n",
    "            if pd.isna(pub) or pd.isna(end) or not (pub <= t < end):\n",
    "                bad_pos = True\n",
    "                break\n",
    "        if bad_pos:\n",
    "            viol_pos_lifespan += 1\n",
    "            if len(viol_pos_lifespan_examples) < max_show:\n",
    "                viol_pos_lifespan_examples.append((idx, row['Time'], row['Impressions_new']))\n",
    "\n",
    "        # 2-5) (보너스) 동일 뉴스ID 중복 여부\n",
    "        if len(news_ids) != len(set(news_ids)):\n",
    "            viol_dup_ids += 1\n",
    "            if len(viol_dup_ids_examples) < max_show:\n",
    "                viol_dup_ids_examples.append((idx, row['Impressions_new']))\n",
    "\n",
    "    # 3) 요약 출력\n",
    "    print(f\"- 총 행수: {total_rows:,}\")\n",
    "    print(f\"[조건1] 허용 집합(9100) 밖 뉴스 포함 행: {viol_not_allowed:,}\")\n",
    "    if viol_not_allowed_examples:\n",
    "        print(\"  예시:\", viol_not_allowed_examples[:max_show])\n",
    "\n",
    "    print(f\"[조건2-양성] 양성(-1) 개수가 1이 아닌 행: {viol_poscount:,}\")\n",
    "    if viol_poscount_examples:\n",
    "        print(\"  예시( idx, pos_cnt, row ):\")\n",
    "        for ex in viol_poscount_examples:\n",
    "            print(\"  \", ex)\n",
    "\n",
    "    print(f\"[조건2-음성] 음성(-0) 개수가 {k_neg}이 아닌 행(양성=1인 경우): {viol_negcount:,}\")\n",
    "    if viol_negcount_examples:\n",
    "        print(\"  예시( idx, neg_cnt, row ):\")\n",
    "        for ex in viol_negcount_examples:\n",
    "            print(\"  \", ex)\n",
    "\n",
    "    print(f\"[조건3-음성수명] Time에 alive가 아닌 음성을 포함한 행: {viol_neg_lifespan:,}\")\n",
    "    if viol_neg_lifespan_examples:\n",
    "        print(\"  예시( idx, Time, row ):\")\n",
    "        for ex in viol_neg_lifespan_examples:\n",
    "            print(\"  \", ex)\n",
    "\n",
    "    print(f\"[옵션-양성수명] Time에 alive가 아닌 양성을 포함한 행: {viol_pos_lifespan:,}\")\n",
    "    if viol_pos_lifespan_examples:\n",
    "        print(\"  예시( idx, Time, row ):\")\n",
    "        for ex in viol_pos_lifespan_examples:\n",
    "            print(\"  \", ex)\n",
    "\n",
    "    print(f\"[보너스] 동일 뉴스ID가 중복으로 들어간 행: {viol_dup_ids:,}\")\n",
    "    if viol_dup_ids_examples:\n",
    "        print(\"  예시:\", viol_dup_ids_examples[:max_show])\n",
    "\n",
    "    print(f\"===== 검증 종료: {split_name} =====\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0122bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 검증 시작: train =====\n",
      "- 총 행수: 236,344\n",
      "[조건1] 허용 집합(9100) 밖 뉴스 포함 행: 0\n",
      "[조건2-양성] 양성(-1) 개수가 1이 아닌 행: 0\n",
      "[조건2-음성] 음성(-0) 개수가 20이 아닌 행(양성=1인 경우): 0\n",
      "[조건3-음성수명] Time에 alive가 아닌 음성을 포함한 행: 0\n",
      "[옵션-양성수명] Time에 alive가 아닌 양성을 포함한 행: 26,796\n",
      "  예시( idx, Time, row ):\n",
      "   (11, Timestamp('2019-11-14 08:38:04'), 'N13553-0 N1257-0 N58620-0 N1160-0 N59073-0 N54368-0 N28072-0 N10480-0 N11204-0 N52945-0 N57248-0 N36793-0 N21535-0 N61622-1 N31893-0 N6937-0 N64305-0 N59138-0 N60986-0 N47380-0 N50012-0')\n",
      "   (35, Timestamp('2019-11-12 08:22:23'), 'N11758-0 N39001-0 N31978-1 N30809-0 N51990-0 N5146-0 N51523-0 N50791-0 N112-0 N14032-0 N42088-0 N11269-0 N43-0 N55355-0 N22829-0 N6953-0 N25748-0 N45456-0 N13902-0 N9322-0 N54993-0')\n",
      "   (42, Timestamp('2019-11-11 11:09:14'), 'N38516-0 N40574-0 N47303-0 N44446-0 N64542-0 N18319-0 N41881-1 N33069-0 N11658-0 N55261-0 N37833-0 N26728-0 N18613-0 N18660-0 N40991-0 N23422-0 N8859-0 N53300-0 N9866-0 N38433-0 N54232-0')\n",
      "   (51, Timestamp('2019-11-11 07:06:30'), 'N49240-0 N43421-0 N27478-0 N12345-0 N38900-0 N14652-0 N53302-0 N56209-0 N39193-0 N42614-0 N31964-0 N15761-0 N21619-0 N33069-0 N18870-1 N45616-0 N46362-0 N9776-0 N9739-0 N2747-0 N19345-0')\n",
      "   (61, Timestamp('2019-11-12 07:10:23'), 'N51154-0 N27289-0 N49529-0 N22891-0 N62873-0 N55261-0 N38350-0 N50791-0 N61839-0 N5434-0 N55041-0 N62688-0 N33619-1 N3377-0 N10869-0 N3304-0 N44528-0 N14093-0 N14592-0 N34203-0 N55304-0')\n",
      "[보너스] 동일 뉴스ID가 중복으로 들어간 행: 0\n",
      "===== 검증 종료: train =====\n",
      "\n",
      "\n",
      "===== 검증 시작: dev =====\n",
      "- 총 행수: 111,383\n",
      "[조건1] 허용 집합(9100) 밖 뉴스 포함 행: 0\n",
      "[조건2-양성] 양성(-1) 개수가 1이 아닌 행: 0\n",
      "[조건2-음성] 음성(-0) 개수가 20이 아닌 행(양성=1인 경우): 0\n",
      "[조건3-음성수명] Time에 alive가 아닌 음성을 포함한 행: 0\n",
      "[옵션-양성수명] Time에 alive가 아닌 양성을 포함한 행: 13,522\n",
      "  예시( idx, Time, row ):\n",
      "   (10, Timestamp('2019-11-15 10:12:44'), 'N38012-0 N14076-0 N46718-0 N46304-0 N6638-0 N42076-0 N62970-0 N11937-0 N45576-0 N25112-0 N12017-0 N2847-0 N3432-0 N57818-1 N19611-0 N56132-0 N16806-0 N39318-0 N53698-0 N19915-0 N28861-0')\n",
      "   (32, Timestamp('2019-11-15 18:54:41'), 'N45612-0 N20236-0 N30466-0 N39928-0 N14266-0 N17870-0 N30840-0 N31594-0 N24017-0 N57415-0 N65145-0 N56315-0 N42723-0 N8560-0 N8427-0 N8616-0 N18311-0 N23617-0 N25639-0 N56023-0 N37204-1')\n",
      "   (33, Timestamp('2019-11-15 18:54:41'), 'N1495-0 N20215-0 N14252-0 N43984-0 N30598-0 N6994-0 N32288-0 N47216-0 N18063-0 N58188-0 N7819-0 N61384-0 N30818-0 N31294-0 N57521-0 N496-1 N164-0 N18995-0 N59868-0 N39776-0 N57415-0')\n",
      "   (39, Timestamp('2019-11-15 07:29:10'), 'N503-0 N14370-0 N1344-0 N436-0 N26202-0 N55405-0 N43277-1 N15492-0 N63773-0 N41288-0 N5078-0 N50719-0 N31856-0 N2636-0 N44687-0 N31018-0 N56166-0 N61292-0 N44145-0 N22726-0 N15066-0')\n",
      "   (41, Timestamp('2019-11-15 14:17:27'), 'N40016-0 N30658-0 N55819-0 N6997-0 N30465-0 N58617-0 N29490-0 N59814-0 N38620-1 N47380-0 N42981-0 N16118-0 N2844-0 N27063-0 N43888-0 N4857-0 N43940-0 N64326-0 N37125-0 N10931-0 N17171-0')\n",
      "[보너스] 동일 뉴스ID가 중복으로 들어간 행: 0\n",
      "===== 검증 종료: dev =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_final = pd.read_csv('train_expanded_global.tsv', sep='\\t')\n",
    "dev_final   = pd.read_csv('dev_expanded_global.tsv',   sep='\\t')\n",
    "validate_split(train_final, 'news_times_global.csv', split_name='train', k_neg=20)\n",
    "validate_split(dev_final, 'news_times_global.csv', split_name='dev', k_neg=20)\n",
    "#validate_split(train_final, 'train_lifespan.csv', split_name='train', k_neg=20)\n",
    "#validate_split(dev_final,   'dev_lifespan.csv',   split_name='dev',   k_neg=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
